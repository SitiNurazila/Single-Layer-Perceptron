{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Import Library"
      ],
      "metadata": {
        "id": "gHVEm8lID1Ag"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import sklearn\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "IFq0TZCGD-Vf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "CmmjOg-cjJ93",
        "outputId": "fe21d814-221d-4c6a-c350-dd01b0dcef24"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     V1  V2       V3       V4       V5       V6       V7       V8       V9  \\\n",
              "0     1   0  0.99539 -0.05889  0.85243  0.02306  0.83398 -0.37708  1.00000   \n",
              "1     1   0  1.00000 -0.18829  0.93035 -0.36156 -0.10868 -0.93597  1.00000   \n",
              "2     1   0  1.00000 -0.03365  1.00000  0.00485  1.00000 -0.12062  0.88965   \n",
              "3     1   0  1.00000 -0.45161  1.00000  1.00000  0.71216 -1.00000  0.00000   \n",
              "4     1   0  1.00000 -0.02401  0.94140  0.06531  0.92106 -0.23255  0.77152   \n",
              "..   ..  ..      ...      ...      ...      ...      ...      ...      ...   \n",
              "346   1   0  0.83508  0.08298  0.73739 -0.14706  0.84349 -0.05567  0.90441   \n",
              "347   1   0  0.95113  0.00419  0.95183 -0.02723  0.93438 -0.01920  0.94590   \n",
              "348   1   0  0.94701 -0.00034  0.93207 -0.03227  0.95177 -0.03431  0.95584   \n",
              "349   1   0  0.90608 -0.01657  0.98122 -0.01989  0.95691 -0.03646  0.85746   \n",
              "350   1   0  0.84710  0.13533  0.73638 -0.06151  0.87873  0.08260  0.88928   \n",
              "\n",
              "         V10  ...      V26      V27      V28      V29      V30      V31  \\\n",
              "0    0.03760  ... -0.51171  0.41078 -0.46168  0.21266 -0.34090  0.42267   \n",
              "1   -0.04549  ... -0.26569 -0.20468 -0.18401 -0.19040 -0.11593 -0.16626   \n",
              "2    0.01198  ... -0.40220  0.58984 -0.22145  0.43100 -0.17365  0.60436   \n",
              "3    0.00000  ...  0.90695  0.51613  1.00000  1.00000 -0.20099  0.25682   \n",
              "4   -0.16399  ... -0.65158  0.13290 -0.53206  0.02431 -0.62197 -0.05707   \n",
              "..       ...  ...      ...      ...      ...      ...      ...      ...   \n",
              "346 -0.04622  ... -0.04202  0.83479  0.00123  1.00000  0.12815  0.86660   \n",
              "347  0.01606  ...  0.01361  0.93522  0.04925  0.93159  0.08168  0.94066   \n",
              "348  0.02446  ...  0.03193  0.92489  0.02542  0.92120  0.02242  0.92459   \n",
              "349  0.00110  ... -0.02099  0.89147 -0.07760  0.82983 -0.17238  0.96022   \n",
              "350 -0.09139  ... -0.15114  0.81147 -0.04822  0.78207 -0.00703  0.75747   \n",
              "\n",
              "         V32      V33      V34  Class  \n",
              "0   -0.54487  0.18641 -0.45300      1  \n",
              "1   -0.06288 -0.13738 -0.02447      0  \n",
              "2   -0.24180  0.56045 -0.38238      1  \n",
              "3    1.00000 -0.32382  1.00000      0  \n",
              "4   -0.59573 -0.04608 -0.65697      1  \n",
              "..       ...      ...      ...    ...  \n",
              "346 -0.10714  0.90546 -0.04307      1  \n",
              "347 -0.00035  0.91483  0.04712      1  \n",
              "348  0.00442  0.92697 -0.00577      1  \n",
              "349 -0.03757  0.87403 -0.16243      1  \n",
              "350 -0.06678  0.85764 -0.06151      1  \n",
              "\n",
              "[351 rows x 35 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-41ef25e8-4d84-413f-840b-4335c5eb84a7\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>V1</th>\n",
              "      <th>V2</th>\n",
              "      <th>V3</th>\n",
              "      <th>V4</th>\n",
              "      <th>V5</th>\n",
              "      <th>V6</th>\n",
              "      <th>V7</th>\n",
              "      <th>V8</th>\n",
              "      <th>V9</th>\n",
              "      <th>V10</th>\n",
              "      <th>...</th>\n",
              "      <th>V26</th>\n",
              "      <th>V27</th>\n",
              "      <th>V28</th>\n",
              "      <th>V29</th>\n",
              "      <th>V30</th>\n",
              "      <th>V31</th>\n",
              "      <th>V32</th>\n",
              "      <th>V33</th>\n",
              "      <th>V34</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.99539</td>\n",
              "      <td>-0.05889</td>\n",
              "      <td>0.85243</td>\n",
              "      <td>0.02306</td>\n",
              "      <td>0.83398</td>\n",
              "      <td>-0.37708</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>0.03760</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.51171</td>\n",
              "      <td>0.41078</td>\n",
              "      <td>-0.46168</td>\n",
              "      <td>0.21266</td>\n",
              "      <td>-0.34090</td>\n",
              "      <td>0.42267</td>\n",
              "      <td>-0.54487</td>\n",
              "      <td>0.18641</td>\n",
              "      <td>-0.45300</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>-0.18829</td>\n",
              "      <td>0.93035</td>\n",
              "      <td>-0.36156</td>\n",
              "      <td>-0.10868</td>\n",
              "      <td>-0.93597</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>-0.04549</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.26569</td>\n",
              "      <td>-0.20468</td>\n",
              "      <td>-0.18401</td>\n",
              "      <td>-0.19040</td>\n",
              "      <td>-0.11593</td>\n",
              "      <td>-0.16626</td>\n",
              "      <td>-0.06288</td>\n",
              "      <td>-0.13738</td>\n",
              "      <td>-0.02447</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>-0.03365</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>0.00485</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>-0.12062</td>\n",
              "      <td>0.88965</td>\n",
              "      <td>0.01198</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.40220</td>\n",
              "      <td>0.58984</td>\n",
              "      <td>-0.22145</td>\n",
              "      <td>0.43100</td>\n",
              "      <td>-0.17365</td>\n",
              "      <td>0.60436</td>\n",
              "      <td>-0.24180</td>\n",
              "      <td>0.56045</td>\n",
              "      <td>-0.38238</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>-0.45161</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>0.71216</td>\n",
              "      <td>-1.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.90695</td>\n",
              "      <td>0.51613</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>-0.20099</td>\n",
              "      <td>0.25682</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>-0.32382</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>-0.02401</td>\n",
              "      <td>0.94140</td>\n",
              "      <td>0.06531</td>\n",
              "      <td>0.92106</td>\n",
              "      <td>-0.23255</td>\n",
              "      <td>0.77152</td>\n",
              "      <td>-0.16399</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.65158</td>\n",
              "      <td>0.13290</td>\n",
              "      <td>-0.53206</td>\n",
              "      <td>0.02431</td>\n",
              "      <td>-0.62197</td>\n",
              "      <td>-0.05707</td>\n",
              "      <td>-0.59573</td>\n",
              "      <td>-0.04608</td>\n",
              "      <td>-0.65697</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>346</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.83508</td>\n",
              "      <td>0.08298</td>\n",
              "      <td>0.73739</td>\n",
              "      <td>-0.14706</td>\n",
              "      <td>0.84349</td>\n",
              "      <td>-0.05567</td>\n",
              "      <td>0.90441</td>\n",
              "      <td>-0.04622</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.04202</td>\n",
              "      <td>0.83479</td>\n",
              "      <td>0.00123</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>0.12815</td>\n",
              "      <td>0.86660</td>\n",
              "      <td>-0.10714</td>\n",
              "      <td>0.90546</td>\n",
              "      <td>-0.04307</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>347</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.95113</td>\n",
              "      <td>0.00419</td>\n",
              "      <td>0.95183</td>\n",
              "      <td>-0.02723</td>\n",
              "      <td>0.93438</td>\n",
              "      <td>-0.01920</td>\n",
              "      <td>0.94590</td>\n",
              "      <td>0.01606</td>\n",
              "      <td>...</td>\n",
              "      <td>0.01361</td>\n",
              "      <td>0.93522</td>\n",
              "      <td>0.04925</td>\n",
              "      <td>0.93159</td>\n",
              "      <td>0.08168</td>\n",
              "      <td>0.94066</td>\n",
              "      <td>-0.00035</td>\n",
              "      <td>0.91483</td>\n",
              "      <td>0.04712</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>348</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.94701</td>\n",
              "      <td>-0.00034</td>\n",
              "      <td>0.93207</td>\n",
              "      <td>-0.03227</td>\n",
              "      <td>0.95177</td>\n",
              "      <td>-0.03431</td>\n",
              "      <td>0.95584</td>\n",
              "      <td>0.02446</td>\n",
              "      <td>...</td>\n",
              "      <td>0.03193</td>\n",
              "      <td>0.92489</td>\n",
              "      <td>0.02542</td>\n",
              "      <td>0.92120</td>\n",
              "      <td>0.02242</td>\n",
              "      <td>0.92459</td>\n",
              "      <td>0.00442</td>\n",
              "      <td>0.92697</td>\n",
              "      <td>-0.00577</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>349</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.90608</td>\n",
              "      <td>-0.01657</td>\n",
              "      <td>0.98122</td>\n",
              "      <td>-0.01989</td>\n",
              "      <td>0.95691</td>\n",
              "      <td>-0.03646</td>\n",
              "      <td>0.85746</td>\n",
              "      <td>0.00110</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.02099</td>\n",
              "      <td>0.89147</td>\n",
              "      <td>-0.07760</td>\n",
              "      <td>0.82983</td>\n",
              "      <td>-0.17238</td>\n",
              "      <td>0.96022</td>\n",
              "      <td>-0.03757</td>\n",
              "      <td>0.87403</td>\n",
              "      <td>-0.16243</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>350</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.84710</td>\n",
              "      <td>0.13533</td>\n",
              "      <td>0.73638</td>\n",
              "      <td>-0.06151</td>\n",
              "      <td>0.87873</td>\n",
              "      <td>0.08260</td>\n",
              "      <td>0.88928</td>\n",
              "      <td>-0.09139</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.15114</td>\n",
              "      <td>0.81147</td>\n",
              "      <td>-0.04822</td>\n",
              "      <td>0.78207</td>\n",
              "      <td>-0.00703</td>\n",
              "      <td>0.75747</td>\n",
              "      <td>-0.06678</td>\n",
              "      <td>0.85764</td>\n",
              "      <td>-0.06151</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>351 rows × 35 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-41ef25e8-4d84-413f-840b-4335c5eb84a7')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-41ef25e8-4d84-413f-840b-4335c5eb84a7 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-41ef25e8-4d84-413f-840b-4335c5eb84a7');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "data = pd.read_csv('ionosphere.csv')\n",
        "data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "id": "jOg68DJ7BmQ2",
        "outputId": "d0c97cee-e661-4430-9056-dd5701454ca5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "               V1     V2          V3          V4          V5          V6  \\\n",
              "count  351.000000  351.0  351.000000  351.000000  351.000000  351.000000   \n",
              "mean     0.891738    0.0    0.641342    0.044372    0.601068    0.115889   \n",
              "std      0.311155    0.0    0.497708    0.441435    0.519862    0.460810   \n",
              "min      0.000000    0.0   -1.000000   -1.000000   -1.000000   -1.000000   \n",
              "25%      1.000000    0.0    0.472135   -0.064735    0.412660   -0.024795   \n",
              "50%      1.000000    0.0    0.871110    0.016310    0.809200    0.022800   \n",
              "75%      1.000000    0.0    1.000000    0.194185    1.000000    0.334655   \n",
              "max      1.000000    0.0    1.000000    1.000000    1.000000    1.000000   \n",
              "\n",
              "               V7          V8          V9         V10  ...         V26  \\\n",
              "count  351.000000  351.000000  351.000000  351.000000  ...  351.000000   \n",
              "mean     0.550095    0.119360    0.511848    0.181345  ...   -0.071187   \n",
              "std      0.492654    0.520750    0.507066    0.483851  ...    0.508495   \n",
              "min     -1.000000   -1.000000   -1.000000   -1.000000  ...   -1.000000   \n",
              "25%      0.211310   -0.054840    0.087110   -0.048075  ...   -0.332390   \n",
              "50%      0.728730    0.014710    0.684210    0.018290  ...   -0.015050   \n",
              "75%      0.969240    0.445675    0.953240    0.534195  ...    0.156765   \n",
              "max      1.000000    1.000000    1.000000    1.000000  ...    1.000000   \n",
              "\n",
              "              V27         V28         V29         V30         V31         V32  \\\n",
              "count  351.000000  351.000000  351.000000  351.000000  351.000000  351.000000   \n",
              "mean     0.541641   -0.069538    0.378445   -0.027907    0.352514   -0.003794   \n",
              "std      0.516205    0.550025    0.575886    0.507974    0.571483    0.513574   \n",
              "min     -1.000000   -1.000000   -1.000000   -1.000000   -1.000000   -1.000000   \n",
              "25%      0.286435   -0.443165    0.000000   -0.236885    0.000000   -0.242595   \n",
              "50%      0.708240   -0.017690    0.496640    0.000000    0.442770    0.000000   \n",
              "75%      0.999945    0.153535    0.883465    0.154075    0.857620    0.200120   \n",
              "max      1.000000    1.000000    1.000000    1.000000    1.000000    1.000000   \n",
              "\n",
              "              V33         V34       Class  \n",
              "count  351.000000  351.000000  351.000000  \n",
              "mean     0.349364    0.014480    0.641026  \n",
              "std      0.522663    0.468337    0.480384  \n",
              "min     -1.000000   -1.000000    0.000000  \n",
              "25%      0.000000   -0.165350    0.000000  \n",
              "50%      0.409560    0.000000    1.000000  \n",
              "75%      0.813765    0.171660    1.000000  \n",
              "max      1.000000    1.000000    1.000000  \n",
              "\n",
              "[8 rows x 35 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-85b2e22f-b0c8-44b0-933a-aadd63f0f65c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>V1</th>\n",
              "      <th>V2</th>\n",
              "      <th>V3</th>\n",
              "      <th>V4</th>\n",
              "      <th>V5</th>\n",
              "      <th>V6</th>\n",
              "      <th>V7</th>\n",
              "      <th>V8</th>\n",
              "      <th>V9</th>\n",
              "      <th>V10</th>\n",
              "      <th>...</th>\n",
              "      <th>V26</th>\n",
              "      <th>V27</th>\n",
              "      <th>V28</th>\n",
              "      <th>V29</th>\n",
              "      <th>V30</th>\n",
              "      <th>V31</th>\n",
              "      <th>V32</th>\n",
              "      <th>V33</th>\n",
              "      <th>V34</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>351.000000</td>\n",
              "      <td>351.0</td>\n",
              "      <td>351.000000</td>\n",
              "      <td>351.000000</td>\n",
              "      <td>351.000000</td>\n",
              "      <td>351.000000</td>\n",
              "      <td>351.000000</td>\n",
              "      <td>351.000000</td>\n",
              "      <td>351.000000</td>\n",
              "      <td>351.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>351.000000</td>\n",
              "      <td>351.000000</td>\n",
              "      <td>351.000000</td>\n",
              "      <td>351.000000</td>\n",
              "      <td>351.000000</td>\n",
              "      <td>351.000000</td>\n",
              "      <td>351.000000</td>\n",
              "      <td>351.000000</td>\n",
              "      <td>351.000000</td>\n",
              "      <td>351.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.891738</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.641342</td>\n",
              "      <td>0.044372</td>\n",
              "      <td>0.601068</td>\n",
              "      <td>0.115889</td>\n",
              "      <td>0.550095</td>\n",
              "      <td>0.119360</td>\n",
              "      <td>0.511848</td>\n",
              "      <td>0.181345</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.071187</td>\n",
              "      <td>0.541641</td>\n",
              "      <td>-0.069538</td>\n",
              "      <td>0.378445</td>\n",
              "      <td>-0.027907</td>\n",
              "      <td>0.352514</td>\n",
              "      <td>-0.003794</td>\n",
              "      <td>0.349364</td>\n",
              "      <td>0.014480</td>\n",
              "      <td>0.641026</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.311155</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.497708</td>\n",
              "      <td>0.441435</td>\n",
              "      <td>0.519862</td>\n",
              "      <td>0.460810</td>\n",
              "      <td>0.492654</td>\n",
              "      <td>0.520750</td>\n",
              "      <td>0.507066</td>\n",
              "      <td>0.483851</td>\n",
              "      <td>...</td>\n",
              "      <td>0.508495</td>\n",
              "      <td>0.516205</td>\n",
              "      <td>0.550025</td>\n",
              "      <td>0.575886</td>\n",
              "      <td>0.507974</td>\n",
              "      <td>0.571483</td>\n",
              "      <td>0.513574</td>\n",
              "      <td>0.522663</td>\n",
              "      <td>0.468337</td>\n",
              "      <td>0.480384</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.472135</td>\n",
              "      <td>-0.064735</td>\n",
              "      <td>0.412660</td>\n",
              "      <td>-0.024795</td>\n",
              "      <td>0.211310</td>\n",
              "      <td>-0.054840</td>\n",
              "      <td>0.087110</td>\n",
              "      <td>-0.048075</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.332390</td>\n",
              "      <td>0.286435</td>\n",
              "      <td>-0.443165</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.236885</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.242595</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.165350</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.871110</td>\n",
              "      <td>0.016310</td>\n",
              "      <td>0.809200</td>\n",
              "      <td>0.022800</td>\n",
              "      <td>0.728730</td>\n",
              "      <td>0.014710</td>\n",
              "      <td>0.684210</td>\n",
              "      <td>0.018290</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.015050</td>\n",
              "      <td>0.708240</td>\n",
              "      <td>-0.017690</td>\n",
              "      <td>0.496640</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.442770</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.409560</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.194185</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.334655</td>\n",
              "      <td>0.969240</td>\n",
              "      <td>0.445675</td>\n",
              "      <td>0.953240</td>\n",
              "      <td>0.534195</td>\n",
              "      <td>...</td>\n",
              "      <td>0.156765</td>\n",
              "      <td>0.999945</td>\n",
              "      <td>0.153535</td>\n",
              "      <td>0.883465</td>\n",
              "      <td>0.154075</td>\n",
              "      <td>0.857620</td>\n",
              "      <td>0.200120</td>\n",
              "      <td>0.813765</td>\n",
              "      <td>0.171660</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows × 35 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-85b2e22f-b0c8-44b0-933a-aadd63f0f65c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-85b2e22f-b0c8-44b0-933a-aadd63f0f65c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-85b2e22f-b0c8-44b0-933a-aadd63f0f65c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = data.drop('Class', axis=1)\n",
        "y = data['Class']\n",
        "print(x)\n",
        "print(y)"
      ],
      "metadata": {
        "id": "jB1iCi1ess6c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c26a66e-4035-443e-83ef-b62512d4d3cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     V1  V2       V3       V4       V5       V6       V7       V8       V9  \\\n",
            "0     1   0  0.99539 -0.05889  0.85243  0.02306  0.83398 -0.37708  1.00000   \n",
            "1     1   0  1.00000 -0.18829  0.93035 -0.36156 -0.10868 -0.93597  1.00000   \n",
            "2     1   0  1.00000 -0.03365  1.00000  0.00485  1.00000 -0.12062  0.88965   \n",
            "3     1   0  1.00000 -0.45161  1.00000  1.00000  0.71216 -1.00000  0.00000   \n",
            "4     1   0  1.00000 -0.02401  0.94140  0.06531  0.92106 -0.23255  0.77152   \n",
            "..   ..  ..      ...      ...      ...      ...      ...      ...      ...   \n",
            "346   1   0  0.83508  0.08298  0.73739 -0.14706  0.84349 -0.05567  0.90441   \n",
            "347   1   0  0.95113  0.00419  0.95183 -0.02723  0.93438 -0.01920  0.94590   \n",
            "348   1   0  0.94701 -0.00034  0.93207 -0.03227  0.95177 -0.03431  0.95584   \n",
            "349   1   0  0.90608 -0.01657  0.98122 -0.01989  0.95691 -0.03646  0.85746   \n",
            "350   1   0  0.84710  0.13533  0.73638 -0.06151  0.87873  0.08260  0.88928   \n",
            "\n",
            "         V10  ...      V25      V26      V27      V28      V29      V30  \\\n",
            "0    0.03760  ...  0.56811 -0.51171  0.41078 -0.46168  0.21266 -0.34090   \n",
            "1   -0.04549  ... -0.20332 -0.26569 -0.20468 -0.18401 -0.19040 -0.11593   \n",
            "2    0.01198  ...  0.57528 -0.40220  0.58984 -0.22145  0.43100 -0.17365   \n",
            "3    0.00000  ...  1.00000  0.90695  0.51613  1.00000  1.00000 -0.20099   \n",
            "4   -0.16399  ...  0.03286 -0.65158  0.13290 -0.53206  0.02431 -0.62197   \n",
            "..       ...  ...      ...      ...      ...      ...      ...      ...   \n",
            "346 -0.04622  ...  0.95378 -0.04202  0.83479  0.00123  1.00000  0.12815   \n",
            "347  0.01606  ...  0.94520  0.01361  0.93522  0.04925  0.93159  0.08168   \n",
            "348  0.02446  ...  0.93988  0.03193  0.92489  0.02542  0.92120  0.02242   \n",
            "349  0.00110  ...  0.91050 -0.02099  0.89147 -0.07760  0.82983 -0.17238   \n",
            "350 -0.09139  ...  0.86467 -0.15114  0.81147 -0.04822  0.78207 -0.00703   \n",
            "\n",
            "         V31      V32      V33      V34  \n",
            "0    0.42267 -0.54487  0.18641 -0.45300  \n",
            "1   -0.16626 -0.06288 -0.13738 -0.02447  \n",
            "2    0.60436 -0.24180  0.56045 -0.38238  \n",
            "3    0.25682  1.00000 -0.32382  1.00000  \n",
            "4   -0.05707 -0.59573 -0.04608 -0.65697  \n",
            "..       ...      ...      ...      ...  \n",
            "346  0.86660 -0.10714  0.90546 -0.04307  \n",
            "347  0.94066 -0.00035  0.91483  0.04712  \n",
            "348  0.92459  0.00442  0.92697 -0.00577  \n",
            "349  0.96022 -0.03757  0.87403 -0.16243  \n",
            "350  0.75747 -0.06678  0.85764 -0.06151  \n",
            "\n",
            "[351 rows x 34 columns]\n",
            "0      1\n",
            "1      0\n",
            "2      1\n",
            "3      0\n",
            "4      1\n",
            "      ..\n",
            "346    1\n",
            "347    1\n",
            "348    1\n",
            "349    1\n",
            "350    1\n",
            "Name: Class, Length: 351, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, Y_train, Y_test = train_test_split(x, y, test_size=151, stratify=y, random_state=0)"
      ],
      "metadata": {
        "id": "OLp7wR7CtVx9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Fungsi mengambil data\n"
      ],
      "metadata": {
        "id": "4itA5QK5LO3Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Modeling"
      ],
      "metadata": {
        "id": "g73eIpzcMIto"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.Sequential()\n",
        "model.add(keras.layers.Dense(units = 1, activation= 'tanh', kernel_initializer = 'he_uniform', input_shape =[34]))\n",
        "opt = keras.optimizers.Adam(learning_rate = 0.01)\n",
        "model.compile(loss ='MSE', optimizer= opt, metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "hzOntDH1MMaw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HtEh76XrMrLf",
        "outputId": "3dcca8b2-4c08-4aaa-e0ba-6734242d4a71"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 1)                 35        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 35\n",
            "Trainable params: 35\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "epoch = 1000\n",
        "hist = model.fit(X_train, Y_train, epochs = epoch, batch_size=32, validation_data=(X_test, Y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NJMhdkOeNEE5",
        "outputId": "913ae7f4-5e49-4095-a23a-d0a19f2fd017"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "7/7 [==============================] - 1s 38ms/step - loss: 0.7177 - accuracy: 0.4050 - val_loss: 0.3400 - val_accuracy: 0.5960\n",
            "Epoch 2/1000\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.2341 - accuracy: 0.6950 - val_loss: 0.2270 - val_accuracy: 0.7086\n",
            "Epoch 3/1000\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1857 - accuracy: 0.7400 - val_loss: 0.2165 - val_accuracy: 0.7219\n",
            "Epoch 4/1000\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.1753 - accuracy: 0.7700 - val_loss: 0.2170 - val_accuracy: 0.7152\n",
            "Epoch 5/1000\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1709 - accuracy: 0.7750 - val_loss: 0.2158 - val_accuracy: 0.7351\n",
            "Epoch 6/1000\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1667 - accuracy: 0.7850 - val_loss: 0.2122 - val_accuracy: 0.7417\n",
            "Epoch 7/1000\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1596 - accuracy: 0.8150 - val_loss: 0.2081 - val_accuracy: 0.7550\n",
            "Epoch 8/1000\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1538 - accuracy: 0.8350 - val_loss: 0.2031 - val_accuracy: 0.7616\n",
            "Epoch 9/1000\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.1480 - accuracy: 0.8350 - val_loss: 0.1990 - val_accuracy: 0.7616\n",
            "Epoch 10/1000\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1426 - accuracy: 0.8350 - val_loss: 0.1948 - val_accuracy: 0.7682\n",
            "Epoch 11/1000\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1380 - accuracy: 0.8450 - val_loss: 0.1912 - val_accuracy: 0.7748\n",
            "Epoch 12/1000\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1340 - accuracy: 0.8550 - val_loss: 0.1887 - val_accuracy: 0.7881\n",
            "Epoch 13/1000\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.1326 - accuracy: 0.8750 - val_loss: 0.1871 - val_accuracy: 0.7881\n",
            "Epoch 14/1000\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.1316 - accuracy: 0.8800 - val_loss: 0.1864 - val_accuracy: 0.7881\n",
            "Epoch 15/1000\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1291 - accuracy: 0.8800 - val_loss: 0.1844 - val_accuracy: 0.7881\n",
            "Epoch 16/1000\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1273 - accuracy: 0.8800 - val_loss: 0.1831 - val_accuracy: 0.8013\n",
            "Epoch 17/1000\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1253 - accuracy: 0.8800 - val_loss: 0.1818 - val_accuracy: 0.8013\n",
            "Epoch 18/1000\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1239 - accuracy: 0.8800 - val_loss: 0.1808 - val_accuracy: 0.7881\n",
            "Epoch 19/1000\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.1230 - accuracy: 0.8850 - val_loss: 0.1797 - val_accuracy: 0.7947\n",
            "Epoch 20/1000\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1217 - accuracy: 0.8850 - val_loss: 0.1796 - val_accuracy: 0.8013\n",
            "Epoch 21/1000\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1207 - accuracy: 0.8900 - val_loss: 0.1783 - val_accuracy: 0.7947\n",
            "Epoch 22/1000\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.1194 - accuracy: 0.8900 - val_loss: 0.1772 - val_accuracy: 0.7947\n",
            "Epoch 23/1000\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1182 - accuracy: 0.8950 - val_loss: 0.1751 - val_accuracy: 0.7881\n",
            "Epoch 24/1000\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1168 - accuracy: 0.8950 - val_loss: 0.1737 - val_accuracy: 0.7881\n",
            "Epoch 25/1000\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1165 - accuracy: 0.8950 - val_loss: 0.1732 - val_accuracy: 0.7881\n",
            "Epoch 26/1000\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1157 - accuracy: 0.8950 - val_loss: 0.1723 - val_accuracy: 0.7881\n",
            "Epoch 27/1000\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.1145 - accuracy: 0.8950 - val_loss: 0.1716 - val_accuracy: 0.7881\n",
            "Epoch 28/1000\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.1131 - accuracy: 0.9000 - val_loss: 0.1701 - val_accuracy: 0.8013\n",
            "Epoch 29/1000\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1125 - accuracy: 0.8950 - val_loss: 0.1685 - val_accuracy: 0.8013\n",
            "Epoch 30/1000\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1110 - accuracy: 0.9000 - val_loss: 0.1673 - val_accuracy: 0.8079\n",
            "Epoch 31/1000\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1101 - accuracy: 0.9000 - val_loss: 0.1663 - val_accuracy: 0.8079\n",
            "Epoch 32/1000\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1092 - accuracy: 0.9050 - val_loss: 0.1657 - val_accuracy: 0.8079\n",
            "Epoch 33/1000\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.1076 - accuracy: 0.9050 - val_loss: 0.1635 - val_accuracy: 0.8146\n",
            "Epoch 34/1000\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.1069 - accuracy: 0.9000 - val_loss: 0.1617 - val_accuracy: 0.8146\n",
            "Epoch 35/1000\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1064 - accuracy: 0.9000 - val_loss: 0.1611 - val_accuracy: 0.8079\n",
            "Epoch 36/1000\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1051 - accuracy: 0.9050 - val_loss: 0.1603 - val_accuracy: 0.8079\n",
            "Epoch 37/1000\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1042 - accuracy: 0.9100 - val_loss: 0.1600 - val_accuracy: 0.8079\n",
            "Epoch 38/1000\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1032 - accuracy: 0.9100 - val_loss: 0.1600 - val_accuracy: 0.8079\n",
            "Epoch 39/1000\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1029 - accuracy: 0.9050 - val_loss: 0.1598 - val_accuracy: 0.8146\n",
            "Epoch 40/1000\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1020 - accuracy: 0.9050 - val_loss: 0.1589 - val_accuracy: 0.8146\n",
            "Epoch 41/1000\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1010 - accuracy: 0.9100 - val_loss: 0.1581 - val_accuracy: 0.8146\n",
            "Epoch 42/1000\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1005 - accuracy: 0.9100 - val_loss: 0.1572 - val_accuracy: 0.8146\n",
            "Epoch 43/1000\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0995 - accuracy: 0.9100 - val_loss: 0.1558 - val_accuracy: 0.8146\n",
            "Epoch 44/1000\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0992 - accuracy: 0.9100 - val_loss: 0.1543 - val_accuracy: 0.8146\n",
            "Epoch 45/1000\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0984 - accuracy: 0.9150 - val_loss: 0.1524 - val_accuracy: 0.8146\n",
            "Epoch 46/1000\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.0975 - accuracy: 0.9200 - val_loss: 0.1512 - val_accuracy: 0.8212\n",
            "Epoch 47/1000\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0970 - accuracy: 0.9250 - val_loss: 0.1508 - val_accuracy: 0.8212\n",
            "Epoch 48/1000\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0962 - accuracy: 0.9300 - val_loss: 0.1498 - val_accuracy: 0.8212\n",
            "Epoch 49/1000\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0956 - accuracy: 0.9300 - val_loss: 0.1490 - val_accuracy: 0.8212\n",
            "Epoch 50/1000\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0947 - accuracy: 0.9250 - val_loss: 0.1479 - val_accuracy: 0.8278\n",
            "Epoch 51/1000\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.0950 - accuracy: 0.9250 - val_loss: 0.1470 - val_accuracy: 0.8278\n",
            "Epoch 52/1000\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.0942 - accuracy: 0.9250 - val_loss: 0.1468 - val_accuracy: 0.8278\n",
            "Epoch 53/1000\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.0942 - accuracy: 0.9250 - val_loss: 0.1465 - val_accuracy: 0.8278\n",
            "Epoch 54/1000\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0934 - accuracy: 0.9350 - val_loss: 0.1451 - val_accuracy: 0.8212\n",
            "Epoch 55/1000\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0923 - accuracy: 0.9350 - val_loss: 0.1444 - val_accuracy: 0.8212\n",
            "Epoch 56/1000\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0922 - accuracy: 0.9300 - val_loss: 0.1436 - val_accuracy: 0.8278\n",
            "Epoch 57/1000\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0915 - accuracy: 0.9350 - val_loss: 0.1434 - val_accuracy: 0.8278\n",
            "Epoch 58/1000\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.0913 - accuracy: 0.9400 - val_loss: 0.1440 - val_accuracy: 0.8278\n",
            "Epoch 59/1000\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0914 - accuracy: 0.9250 - val_loss: 0.1436 - val_accuracy: 0.8344\n",
            "Epoch 60/1000\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0913 - accuracy: 0.9250 - val_loss: 0.1424 - val_accuracy: 0.8344\n",
            "Epoch 61/1000\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.0907 - accuracy: 0.9300 - val_loss: 0.1427 - val_accuracy: 0.8278\n",
            "Epoch 62/1000\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0905 - accuracy: 0.9250 - val_loss: 0.1432 - val_accuracy: 0.8278\n",
            "Epoch 63/1000\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0912 - accuracy: 0.9250 - val_loss: 0.1432 - val_accuracy: 0.8278\n",
            "Epoch 64/1000\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0905 - accuracy: 0.9300 - val_loss: 0.1433 - val_accuracy: 0.8278\n",
            "Epoch 65/1000\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0898 - accuracy: 0.9250 - val_loss: 0.1430 - val_accuracy: 0.8344\n",
            "Epoch 66/1000\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0897 - accuracy: 0.9250 - val_loss: 0.1428 - val_accuracy: 0.8278\n",
            "Epoch 67/1000\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0894 - accuracy: 0.9250 - val_loss: 0.1428 - val_accuracy: 0.8278\n",
            "Epoch 68/1000\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0892 - accuracy: 0.9250 - val_loss: 0.1427 - val_accuracy: 0.8344\n",
            "Epoch 69/1000\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0890 - accuracy: 0.9250 - val_loss: 0.1428 - val_accuracy: 0.8278\n",
            "Epoch 70/1000\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0892 - accuracy: 0.9200 - val_loss: 0.1425 - val_accuracy: 0.8212\n",
            "Epoch 71/1000\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0894 - accuracy: 0.9250 - val_loss: 0.1425 - val_accuracy: 0.8212\n",
            "Epoch 72/1000\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0896 - accuracy: 0.9250 - val_loss: 0.1416 - val_accuracy: 0.8278\n",
            "Epoch 73/1000\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0887 - accuracy: 0.9250 - val_loss: 0.1412 - val_accuracy: 0.8212\n",
            "Epoch 74/1000\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0886 - accuracy: 0.9200 - val_loss: 0.1416 - val_accuracy: 0.8212\n",
            "Epoch 75/1000\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0887 - accuracy: 0.9200 - val_loss: 0.1401 - val_accuracy: 0.8278\n",
            "Epoch 76/1000\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0899 - accuracy: 0.9250 - val_loss: 0.1397 - val_accuracy: 0.8411\n",
            "Epoch 77/1000\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0884 - accuracy: 0.9250 - val_loss: 0.1409 - val_accuracy: 0.8278\n",
            "Epoch 78/1000\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0883 - accuracy: 0.9250 - val_loss: 0.1424 - val_accuracy: 0.8212\n",
            "Epoch 79/1000\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0880 - accuracy: 0.9300 - val_loss: 0.1415 - val_accuracy: 0.8212\n",
            "Epoch 80/1000\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0880 - accuracy: 0.9300 - val_loss: 0.1408 - val_accuracy: 0.8278\n",
            "Epoch 81/1000\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.0877 - accuracy: 0.9250 - val_loss: 0.1404 - val_accuracy: 0.8344\n",
            "Epoch 82/1000\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0890 - accuracy: 0.9350 - val_loss: 0.1395 - val_accuracy: 0.8344\n",
            "Epoch 83/1000\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0883 - accuracy: 0.9300 - val_loss: 0.1402 - val_accuracy: 0.8278\n",
            "Epoch 84/1000\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0882 - accuracy: 0.9250 - val_loss: 0.1407 - val_accuracy: 0.8212\n",
            "Epoch 85/1000\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0875 - accuracy: 0.9300 - val_loss: 0.1402 - val_accuracy: 0.8411\n",
            "Epoch 86/1000\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0876 - accuracy: 0.9250 - val_loss: 0.1406 - val_accuracy: 0.8411\n",
            "Epoch 87/1000\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0874 - accuracy: 0.9250 - val_loss: 0.1411 - val_accuracy: 0.8411\n",
            "Epoch 88/1000\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0870 - accuracy: 0.9250 - val_loss: 0.1418 - val_accuracy: 0.8278\n",
            "Epoch 89/1000\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.0878 - accuracy: 0.9200 - val_loss: 0.1425 - val_accuracy: 0.8278\n",
            "Epoch 90/1000\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0878 - accuracy: 0.9200 - val_loss: 0.1404 - val_accuracy: 0.8411\n",
            "Epoch 91/1000\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0869 - accuracy: 0.9250 - val_loss: 0.1406 - val_accuracy: 0.8344\n",
            "Epoch 92/1000\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0867 - accuracy: 0.9250 - val_loss: 0.1411 - val_accuracy: 0.8344\n",
            "Epoch 93/1000\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0867 - accuracy: 0.9200 - val_loss: 0.1417 - val_accuracy: 0.8278\n",
            "Epoch 94/1000\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0870 - accuracy: 0.9200 - val_loss: 0.1412 - val_accuracy: 0.8278\n",
            "Epoch 95/1000\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0868 - accuracy: 0.9200 - val_loss: 0.1408 - val_accuracy: 0.8411\n",
            "Epoch 96/1000\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.0867 - accuracy: 0.9300 - val_loss: 0.1409 - val_accuracy: 0.8344\n",
            "Epoch 97/1000\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0868 - accuracy: 0.9300 - val_loss: 0.1416 - val_accuracy: 0.8344\n",
            "Epoch 98/1000\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0864 - accuracy: 0.9250 - val_loss: 0.1419 - val_accuracy: 0.8344\n",
            "Epoch 99/1000\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0862 - accuracy: 0.9250 - val_loss: 0.1413 - val_accuracy: 0.8344\n",
            "Epoch 100/1000\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.0865 - accuracy: 0.9250 - val_loss: 0.1402 - val_accuracy: 0.8278\n",
            "Epoch 101/1000\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.0866 - accuracy: 0.9250 - val_loss: 0.1411 - val_accuracy: 0.8212\n",
            "Epoch 102/1000\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0864 - accuracy: 0.9250 - val_loss: 0.1413 - val_accuracy: 0.8344\n",
            "Epoch 103/1000\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0862 - accuracy: 0.9250 - val_loss: 0.1412 - val_accuracy: 0.8344\n",
            "Epoch 104/1000\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0864 - accuracy: 0.9250 - val_loss: 0.1418 - val_accuracy: 0.8278\n",
            "Epoch 105/1000\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0867 - accuracy: 0.9250 - val_loss: 0.1427 - val_accuracy: 0.8146\n",
            "Epoch 106/1000\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0861 - accuracy: 0.9250 - val_loss: 0.1412 - val_accuracy: 0.8278\n",
            "Epoch 107/1000\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0865 - accuracy: 0.9250 - val_loss: 0.1412 - val_accuracy: 0.8212\n",
            "Epoch 108/1000\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0860 - accuracy: 0.9250 - val_loss: 0.1401 - val_accuracy: 0.8278\n",
            "Epoch 109/1000\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0862 - accuracy: 0.9300 - val_loss: 0.1405 - val_accuracy: 0.8411\n",
            "Epoch 110/1000\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0858 - accuracy: 0.9300 - val_loss: 0.1416 - val_accuracy: 0.8477\n",
            "Epoch 111/1000\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.0861 - accuracy: 0.9300 - val_loss: 0.1418 - val_accuracy: 0.8344\n",
            "Epoch 112/1000\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0859 - accuracy: 0.9250 - val_loss: 0.1427 - val_accuracy: 0.8278\n",
            "Epoch 113/1000\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0855 - accuracy: 0.9300 - val_loss: 0.1416 - val_accuracy: 0.8278\n",
            "Epoch 114/1000\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0862 - accuracy: 0.9300 - val_loss: 0.1418 - val_accuracy: 0.8411\n",
            "Epoch 115/1000\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0862 - accuracy: 0.9250 - val_loss: 0.1418 - val_accuracy: 0.8411\n",
            "Epoch 116/1000\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0857 - accuracy: 0.9300 - val_loss: 0.1416 - val_accuracy: 0.8344\n",
            "Epoch 117/1000\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0861 - accuracy: 0.9250 - val_loss: 0.1422 - val_accuracy: 0.8212\n",
            "Epoch 118/1000\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0857 - accuracy: 0.9250 - val_loss: 0.1409 - val_accuracy: 0.8344\n",
            "Epoch 119/1000\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0858 - accuracy: 0.9250 - val_loss: 0.1401 - val_accuracy: 0.8344\n",
            "Epoch 120/1000\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0858 - accuracy: 0.9250 - val_loss: 0.1397 - val_accuracy: 0.8411\n",
            "Epoch 121/1000\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.0859 - accuracy: 0.9300 - val_loss: 0.1401 - val_accuracy: 0.8344\n",
            "Epoch 122/1000\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0854 - accuracy: 0.9300 - val_loss: 0.1402 - val_accuracy: 0.8278\n",
            "Epoch 123/1000\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0850 - accuracy: 0.9300 - val_loss: 0.1401 - val_accuracy: 0.8477\n",
            "Epoch 124/1000\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0853 - accuracy: 0.9350 - val_loss: 0.1393 - val_accuracy: 0.8477\n",
            "Epoch 125/1000\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0855 - accuracy: 0.9400 - val_loss: 0.1389 - val_accuracy: 0.8411\n",
            "Epoch 126/1000\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0854 - accuracy: 0.9350 - val_loss: 0.1395 - val_accuracy: 0.8477\n",
            "Epoch 127/1000\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0855 - accuracy: 0.9350 - val_loss: 0.1395 - val_accuracy: 0.8411\n",
            "Epoch 128/1000\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0859 - accuracy: 0.9250 - val_loss: 0.1396 - val_accuracy: 0.8411\n",
            "Epoch 129/1000\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0858 - accuracy: 0.9250 - val_loss: 0.1393 - val_accuracy: 0.8411\n",
            "Epoch 130/1000\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0850 - accuracy: 0.9250 - val_loss: 0.1399 - val_accuracy: 0.8411\n",
            "Epoch 131/1000\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0847 - accuracy: 0.9250 - val_loss: 0.1406 - val_accuracy: 0.8411\n",
            "Epoch 132/1000\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0844 - accuracy: 0.9300 - val_loss: 0.1403 - val_accuracy: 0.8411\n",
            "Epoch 133/1000\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0845 - accuracy: 0.9300 - val_loss: 0.1405 - val_accuracy: 0.8411\n",
            "Epoch 134/1000\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0845 - accuracy: 0.9250 - val_loss: 0.1402 - val_accuracy: 0.8477\n",
            "Epoch 135/1000\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0852 - accuracy: 0.9250 - val_loss: 0.1418 - val_accuracy: 0.8411\n",
            "Epoch 136/1000\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.0844 - accuracy: 0.9250 - val_loss: 0.1430 - val_accuracy: 0.8344\n",
            "Epoch 137/1000\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0849 - accuracy: 0.9250 - val_loss: 0.1436 - val_accuracy: 0.8411\n",
            "Epoch 138/1000\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0852 - accuracy: 0.9250 - val_loss: 0.1448 - val_accuracy: 0.8344\n",
            "Epoch 139/1000\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0849 - accuracy: 0.9250 - val_loss: 0.1447 - val_accuracy: 0.8278\n",
            "Epoch 140/1000\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0852 - accuracy: 0.9250 - val_loss: 0.1458 - val_accuracy: 0.8212\n",
            "Epoch 141/1000\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0847 - accuracy: 0.9250 - val_loss: 0.1452 - val_accuracy: 0.8278\n",
            "Epoch 142/1000\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0841 - accuracy: 0.9250 - val_loss: 0.1449 - val_accuracy: 0.8278\n",
            "Epoch 143/1000\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0846 - accuracy: 0.9250 - val_loss: 0.1446 - val_accuracy: 0.8344\n",
            "Epoch 144/1000\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0851 - accuracy: 0.9250 - val_loss: 0.1449 - val_accuracy: 0.8212\n",
            "Epoch 145/1000\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.0843 - accuracy: 0.9250 - val_loss: 0.1442 - val_accuracy: 0.8278\n",
            "Epoch 146/1000\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0844 - accuracy: 0.9300 - val_loss: 0.1442 - val_accuracy: 0.8278\n",
            "Epoch 147/1000\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0847 - accuracy: 0.9250 - val_loss: 0.1448 - val_accuracy: 0.8212\n",
            "Epoch 148/1000\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.0834 - accuracy: 0.9350 - val_loss: 0.1441 - val_accuracy: 0.8278\n",
            "Epoch 149/1000\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.0856 - accuracy: 0.9350 - val_loss: 0.1433 - val_accuracy: 0.8344\n",
            "Epoch 150/1000\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0844 - accuracy: 0.9350 - val_loss: 0.1434 - val_accuracy: 0.8278\n",
            "Epoch 151/1000\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0847 - accuracy: 0.9300 - val_loss: 0.1432 - val_accuracy: 0.8278\n",
            "Epoch 152/1000\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0845 - accuracy: 0.9300 - val_loss: 0.1423 - val_accuracy: 0.8344\n",
            "Epoch 153/1000\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0847 - accuracy: 0.9350 - val_loss: 0.1432 - val_accuracy: 0.8278\n",
            "Epoch 154/1000\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0841 - accuracy: 0.9350 - val_loss: 0.1436 - val_accuracy: 0.8344\n",
            "Epoch 155/1000\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.0841 - accuracy: 0.9350 - val_loss: 0.1433 - val_accuracy: 0.8278\n",
            "Epoch 156/1000\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.0843 - accuracy: 0.9350 - val_loss: 0.1428 - val_accuracy: 0.8278\n",
            "Epoch 157/1000\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.0843 - accuracy: 0.9350 - val_loss: 0.1429 - val_accuracy: 0.8278\n",
            "Epoch 158/1000\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.0839 - accuracy: 0.9250 - val_loss: 0.1431 - val_accuracy: 0.8278\n",
            "Epoch 159/1000\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0842 - accuracy: 0.9250 - val_loss: 0.1438 - val_accuracy: 0.8278\n",
            "Epoch 160/1000\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.0842 - accuracy: 0.9250 - val_loss: 0.1444 - val_accuracy: 0.8278\n",
            "Epoch 161/1000\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0848 - accuracy: 0.9300 - val_loss: 0.1448 - val_accuracy: 0.8278\n",
            "Epoch 162/1000\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0849 - accuracy: 0.9200 - val_loss: 0.1446 - val_accuracy: 0.8278\n",
            "Epoch 163/1000\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0838 - accuracy: 0.9300 - val_loss: 0.1441 - val_accuracy: 0.8344\n",
            "Epoch 164/1000\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0845 - accuracy: 0.9300 - val_loss: 0.1441 - val_accuracy: 0.8344\n",
            "Epoch 165/1000\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0836 - accuracy: 0.9250 - val_loss: 0.1446 - val_accuracy: 0.8344\n",
            "Epoch 166/1000\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0845 - accuracy: 0.9200 - val_loss: 0.1436 - val_accuracy: 0.8344\n",
            "Epoch 167/1000\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0841 - accuracy: 0.9250 - val_loss: 0.1441 - val_accuracy: 0.8344\n",
            "Epoch 168/1000\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0838 - accuracy: 0.9300 - val_loss: 0.1442 - val_accuracy: 0.8344\n",
            "Epoch 169/1000\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.0840 - accuracy: 0.9300 - val_loss: 0.1450 - val_accuracy: 0.8344\n",
            "Epoch 170/1000\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0839 - accuracy: 0.9350 - val_loss: 0.1441 - val_accuracy: 0.8344\n",
            "Epoch 171/1000\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0839 - accuracy: 0.9350 - val_loss: 0.1446 - val_accuracy: 0.8344\n",
            "Epoch 172/1000\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0846 - accuracy: 0.9300 - val_loss: 0.1451 - val_accuracy: 0.8278\n",
            "Epoch 173/1000\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0837 - accuracy: 0.9300 - val_loss: 0.1461 - val_accuracy: 0.8344\n",
            "Epoch 174/1000\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0843 - accuracy: 0.9200 - val_loss: 0.1462 - val_accuracy: 0.8344\n",
            "Epoch 175/1000\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.0847 - accuracy: 0.9350 - val_loss: 0.1451 - val_accuracy: 0.8344\n",
            "Epoch 176/1000\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0841 - accuracy: 0.9350 - val_loss: 0.1440 - val_accuracy: 0.8344\n",
            "Epoch 177/1000\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0846 - accuracy: 0.9250 - val_loss: 0.1444 - val_accuracy: 0.8344\n",
            "Epoch 178/1000\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.0845 - accuracy: 0.9200 - val_loss: 0.1442 - val_accuracy: 0.8344\n",
            "Epoch 179/1000\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0855 - accuracy: 0.9300 - val_loss: 0.1433 - val_accuracy: 0.8344\n",
            "Epoch 180/1000\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0849 - accuracy: 0.9300 - val_loss: 0.1439 - val_accuracy: 0.8278\n",
            "Epoch 181/1000\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0843 - accuracy: 0.9250 - val_loss: 0.1416 - val_accuracy: 0.8344\n",
            "Epoch 182/1000\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0842 - accuracy: 0.9250 - val_loss: 0.1418 - val_accuracy: 0.8344\n",
            "Epoch 183/1000\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0841 - accuracy: 0.9250 - val_loss: 0.1425 - val_accuracy: 0.8344\n",
            "Epoch 184/1000\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0836 - accuracy: 0.9250 - val_loss: 0.1431 - val_accuracy: 0.8278\n",
            "Epoch 185/1000\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.0842 - accuracy: 0.9250 - val_loss: 0.1438 - val_accuracy: 0.8278\n",
            "Epoch 186/1000\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0835 - accuracy: 0.9250 - val_loss: 0.1446 - val_accuracy: 0.8344\n",
            "Epoch 187/1000\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0834 - accuracy: 0.9250 - val_loss: 0.1456 - val_accuracy: 0.8344\n",
            "Epoch 188/1000\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0842 - accuracy: 0.9150 - val_loss: 0.1453 - val_accuracy: 0.8344\n",
            "Epoch 189/1000\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0832 - accuracy: 0.9300 - val_loss: 0.1438 - val_accuracy: 0.8278\n",
            "Epoch 190/1000\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0848 - accuracy: 0.9300 - val_loss: 0.1436 - val_accuracy: 0.8278\n",
            "Epoch 191/1000\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0836 - accuracy: 0.9300 - val_loss: 0.1445 - val_accuracy: 0.8344\n",
            "Epoch 192/1000\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0848 - accuracy: 0.9200 - val_loss: 0.1469 - val_accuracy: 0.8344\n",
            "Epoch 193/1000\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0846 - accuracy: 0.9250 - val_loss: 0.1453 - val_accuracy: 0.8344\n",
            "Epoch 194/1000\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0842 - accuracy: 0.9300 - val_loss: 0.1459 - val_accuracy: 0.8344\n",
            "Epoch 195/1000\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0833 - accuracy: 0.9300 - val_loss: 0.1457 - val_accuracy: 0.8344\n",
            "Epoch 196/1000\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0833 - accuracy: 0.9300 - val_loss: 0.1443 - val_accuracy: 0.8278\n",
            "Epoch 197/1000\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0834 - accuracy: 0.9250 - val_loss: 0.1439 - val_accuracy: 0.8344\n",
            "Epoch 198/1000\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.0831 - accuracy: 0.9300 - val_loss: 0.1450 - val_accuracy: 0.8344\n",
            "Epoch 199/1000\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0837 - accuracy: 0.9300 - val_loss: 0.1457 - val_accuracy: 0.8278\n",
            "Epoch 200/1000\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0847 - accuracy: 0.9350 - val_loss: 0.1464 - val_accuracy: 0.8212\n",
            "Epoch 201/1000\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.0843 - accuracy: 0.9300 - val_loss: 0.1470 - val_accuracy: 0.8411\n",
            "Epoch 202/1000\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0838 - accuracy: 0.9200 - val_loss: 0.1474 - val_accuracy: 0.8344\n",
            "Epoch 203/1000\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0837 - accuracy: 0.9250 - val_loss: 0.1465 - val_accuracy: 0.8278\n",
            "Epoch 204/1000\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0831 - accuracy: 0.9300 - val_loss: 0.1469 - val_accuracy: 0.8212\n",
            "Epoch 205/1000\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0833 - accuracy: 0.9300 - val_loss: 0.1485 - val_accuracy: 0.8278\n",
            "Epoch 206/1000\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0832 - accuracy: 0.9250 - val_loss: 0.1486 - val_accuracy: 0.8278\n",
            "Epoch 207/1000\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0832 - accuracy: 0.9250 - val_loss: 0.1486 - val_accuracy: 0.8278\n",
            "Epoch 208/1000\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0834 - accuracy: 0.9350 - val_loss: 0.1487 - val_accuracy: 0.8212\n",
            "Epoch 209/1000\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0834 - accuracy: 0.9200 - val_loss: 0.1481 - val_accuracy: 0.8278\n",
            "Epoch 210/1000\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0832 - accuracy: 0.9250 - val_loss: 0.1494 - val_accuracy: 0.8278\n",
            "Epoch 211/1000\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0832 - accuracy: 0.9250 - val_loss: 0.1513 - val_accuracy: 0.8278\n",
            "Epoch 212/1000\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0844 - accuracy: 0.9250 - val_loss: 0.1520 - val_accuracy: 0.8344\n",
            "Epoch 213/1000\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0831 - accuracy: 0.9250 - val_loss: 0.1519 - val_accuracy: 0.8212\n",
            "Epoch 214/1000\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0849 - accuracy: 0.9350 - val_loss: 0.1512 - val_accuracy: 0.8212\n",
            "Epoch 215/1000\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0831 - accuracy: 0.9250 - val_loss: 0.1522 - val_accuracy: 0.8212\n",
            "Epoch 216/1000\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0835 - accuracy: 0.9200 - val_loss: 0.1502 - val_accuracy: 0.8278\n",
            "Epoch 217/1000\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0830 - accuracy: 0.9250 - val_loss: 0.1495 - val_accuracy: 0.8278\n",
            "Epoch 218/1000\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0834 - accuracy: 0.9300 - val_loss: 0.1499 - val_accuracy: 0.8278\n",
            "Epoch 219/1000\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.0828 - accuracy: 0.9200 - val_loss: 0.1513 - val_accuracy: 0.8212\n",
            "Epoch 220/1000\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0834 - accuracy: 0.9150 - val_loss: 0.1509 - val_accuracy: 0.8212\n",
            "Epoch 221/1000\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.0831 - accuracy: 0.9200 - val_loss: 0.1510 - val_accuracy: 0.8278\n",
            "Epoch 222/1000\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0830 - accuracy: 0.9300 - val_loss: 0.1515 - val_accuracy: 0.8278\n",
            "Epoch 223/1000\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0827 - accuracy: 0.9300 - val_loss: 0.1521 - val_accuracy: 0.8278\n",
            "Epoch 224/1000\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0833 - accuracy: 0.9300 - val_loss: 0.1520 - val_accuracy: 0.8278\n",
            "Epoch 225/1000\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.0820 - accuracy: 0.9250 - val_loss: 0.1522 - val_accuracy: 0.8212\n",
            "Epoch 226/1000\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0842 - accuracy: 0.9200 - val_loss: 0.1519 - val_accuracy: 0.8212\n",
            "Epoch 227/1000\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0837 - accuracy: 0.9200 - val_loss: 0.1492 - val_accuracy: 0.8344\n",
            "Epoch 228/1000\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0841 - accuracy: 0.9300 - val_loss: 0.1494 - val_accuracy: 0.8212\n",
            "Epoch 229/1000\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.0832 - accuracy: 0.9250 - val_loss: 0.1504 - val_accuracy: 0.8212\n",
            "Epoch 230/1000\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0827 - accuracy: 0.9250 - val_loss: 0.1511 - val_accuracy: 0.8146\n",
            "Epoch 231/1000\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0826 - accuracy: 0.9350 - val_loss: 0.1515 - val_accuracy: 0.8212\n",
            "Epoch 232/1000\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0838 - accuracy: 0.9350 - val_loss: 0.1508 - val_accuracy: 0.8344\n",
            "Epoch 233/1000\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0822 - accuracy: 0.9300 - val_loss: 0.1526 - val_accuracy: 0.8278\n",
            "Epoch 234/1000\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.0832 - accuracy: 0.9200 - val_loss: 0.1532 - val_accuracy: 0.8278\n",
            "Epoch 235/1000\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0831 - accuracy: 0.9200 - val_loss: 0.1523 - val_accuracy: 0.8344\n",
            "Epoch 236/1000\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.0825 - accuracy: 0.9300 - val_loss: 0.1528 - val_accuracy: 0.8344\n",
            "Epoch 237/1000\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0821 - accuracy: 0.9300 - val_loss: 0.1534 - val_accuracy: 0.8278\n",
            "Epoch 238/1000\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0836 - accuracy: 0.9300 - val_loss: 0.1550 - val_accuracy: 0.8278\n",
            "Epoch 239/1000\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0833 - accuracy: 0.9300 - val_loss: 0.1545 - val_accuracy: 0.8278\n",
            "Epoch 240/1000\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.0830 - accuracy: 0.9300 - val_loss: 0.1546 - val_accuracy: 0.8278\n",
            "Epoch 241/1000\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0833 - accuracy: 0.9250 - val_loss: 0.1547 - val_accuracy: 0.8278\n",
            "Epoch 242/1000\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0832 - accuracy: 0.9250 - val_loss: 0.1539 - val_accuracy: 0.8278\n",
            "Epoch 243/1000\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0829 - accuracy: 0.9250 - val_loss: 0.1540 - val_accuracy: 0.8344\n",
            "Epoch 244/1000\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0828 - accuracy: 0.9300 - val_loss: 0.1535 - val_accuracy: 0.8278\n",
            "Epoch 245/1000\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0833 - accuracy: 0.9350 - val_loss: 0.1537 - val_accuracy: 0.8278\n",
            "Epoch 246/1000\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0831 - accuracy: 0.9250 - val_loss: 0.1548 - val_accuracy: 0.8212\n",
            "Epoch 247/1000\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.0828 - accuracy: 0.9300 - val_loss: 0.1537 - val_accuracy: 0.8212\n",
            "Epoch 248/1000\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0830 - accuracy: 0.9300 - val_loss: 0.1552 - val_accuracy: 0.8212\n",
            "Epoch 249/1000\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.0835 - accuracy: 0.9250 - val_loss: 0.1561 - val_accuracy: 0.8278\n",
            "Epoch 250/1000\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0829 - accuracy: 0.9250 - val_loss: 0.1555 - val_accuracy: 0.8344\n",
            "Epoch 251/1000\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0829 - accuracy: 0.9250 - val_loss: 0.1545 - val_accuracy: 0.8344\n",
            "Epoch 252/1000\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0828 - accuracy: 0.9250 - val_loss: 0.1554 - val_accuracy: 0.8344\n",
            "Epoch 253/1000\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0827 - accuracy: 0.9250 - val_loss: 0.1573 - val_accuracy: 0.8278\n",
            "Epoch 254/1000\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.0832 - accuracy: 0.9250 - val_loss: 0.1560 - val_accuracy: 0.8344\n",
            "Epoch 255/1000\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0828 - accuracy: 0.9300 - val_loss: 0.1565 - val_accuracy: 0.8278\n",
            "Epoch 256/1000\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0832 - accuracy: 0.9300 - val_loss: 0.1560 - val_accuracy: 0.8212\n",
            "Epoch 257/1000\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0823 - accuracy: 0.9300 - val_loss: 0.1570 - val_accuracy: 0.8212\n",
            "Epoch 258/1000\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0830 - accuracy: 0.9200 - val_loss: 0.1565 - val_accuracy: 0.8278\n",
            "Epoch 259/1000\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.0833 - accuracy: 0.9300 - val_loss: 0.1560 - val_accuracy: 0.8344\n",
            "Epoch 260/1000\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0828 - accuracy: 0.9300 - val_loss: 0.1556 - val_accuracy: 0.8344\n",
            "Epoch 261/1000\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.0826 - accuracy: 0.9200 - val_loss: 0.1567 - val_accuracy: 0.8212\n",
            "Epoch 262/1000\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.0823 - accuracy: 0.9200 - val_loss: 0.1563 - val_accuracy: 0.8278\n",
            "Epoch 263/1000\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0828 - accuracy: 0.9300 - val_loss: 0.1562 - val_accuracy: 0.8212\n",
            "Epoch 264/1000\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.0821 - accuracy: 0.9300 - val_loss: 0.1566 - val_accuracy: 0.8212\n",
            "Epoch 265/1000\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0825 - accuracy: 0.9250 - val_loss: 0.1566 - val_accuracy: 0.8212\n",
            "Epoch 266/1000\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0820 - accuracy: 0.9300 - val_loss: 0.1578 - val_accuracy: 0.8212\n",
            "Epoch 267/1000\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0824 - accuracy: 0.9300 - val_loss: 0.1589 - val_accuracy: 0.8344\n",
            "Epoch 268/1000\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0823 - accuracy: 0.9300 - val_loss: 0.1589 - val_accuracy: 0.8278\n",
            "Epoch 269/1000\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0825 - accuracy: 0.9300 - val_loss: 0.1578 - val_accuracy: 0.8344\n",
            "Epoch 270/1000\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0823 - accuracy: 0.9300 - val_loss: 0.1582 - val_accuracy: 0.8278\n",
            "Epoch 271/1000\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.0827 - accuracy: 0.9300 - val_loss: 0.1580 - val_accuracy: 0.8344\n",
            "Epoch 272/1000\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0835 - accuracy: 0.9250 - val_loss: 0.1584 - val_accuracy: 0.8344\n",
            "Epoch 273/1000\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0829 - accuracy: 0.9250 - val_loss: 0.1596 - val_accuracy: 0.8212\n",
            "Epoch 274/1000\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0829 - accuracy: 0.9250 - val_loss: 0.1609 - val_accuracy: 0.8278\n",
            "Epoch 275/1000\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.0826 - accuracy: 0.9250 - val_loss: 0.1607 - val_accuracy: 0.8212\n",
            "Epoch 276/1000\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0830 - accuracy: 0.9250 - val_loss: 0.1588 - val_accuracy: 0.8212\n",
            "Epoch 277/1000\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0833 - accuracy: 0.9250 - val_loss: 0.1580 - val_accuracy: 0.8278\n",
            "Epoch 278/1000\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0823 - accuracy: 0.9300 - val_loss: 0.1580 - val_accuracy: 0.8278\n",
            "Epoch 279/1000\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0829 - accuracy: 0.9200 - val_loss: 0.1589 - val_accuracy: 0.8212\n",
            "Epoch 280/1000\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0824 - accuracy: 0.9200 - val_loss: 0.1575 - val_accuracy: 0.8212\n",
            "Epoch 281/1000\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0823 - accuracy: 0.9300 - val_loss: 0.1567 - val_accuracy: 0.8212\n",
            "Epoch 282/1000\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0827 - accuracy: 0.9350 - val_loss: 0.1570 - val_accuracy: 0.8278\n",
            "Epoch 283/1000\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0829 - accuracy: 0.9250 - val_loss: 0.1571 - val_accuracy: 0.8278\n",
            "Epoch 284/1000\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0828 - accuracy: 0.9200 - val_loss: 0.1569 - val_accuracy: 0.8344\n",
            "Epoch 285/1000\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0834 - accuracy: 0.9300 - val_loss: 0.1567 - val_accuracy: 0.8344\n",
            "Epoch 286/1000\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0832 - accuracy: 0.9250 - val_loss: 0.1569 - val_accuracy: 0.8344\n",
            "Epoch 287/1000\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0827 - accuracy: 0.9250 - val_loss: 0.1568 - val_accuracy: 0.8344\n",
            "Epoch 288/1000\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0820 - accuracy: 0.9250 - val_loss: 0.1566 - val_accuracy: 0.8411\n",
            "Epoch 289/1000\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0833 - accuracy: 0.9200 - val_loss: 0.1570 - val_accuracy: 0.8344\n",
            "Epoch 290/1000\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0831 - accuracy: 0.9250 - val_loss: 0.1571 - val_accuracy: 0.8212\n",
            "Epoch 291/1000\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0824 - accuracy: 0.9200 - val_loss: 0.1577 - val_accuracy: 0.8278\n",
            "Epoch 292/1000\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.0817 - accuracy: 0.9300 - val_loss: 0.1578 - val_accuracy: 0.8278\n",
            "Epoch 293/1000\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.0831 - accuracy: 0.9300 - val_loss: 0.1581 - val_accuracy: 0.8212\n",
            "Epoch 294/1000\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0826 - accuracy: 0.9250 - val_loss: 0.1569 - val_accuracy: 0.8278\n",
            "Epoch 295/1000\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0825 - accuracy: 0.9250 - val_loss: 0.1562 - val_accuracy: 0.8278\n",
            "Epoch 296/1000\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0825 - accuracy: 0.9300 - val_loss: 0.1556 - val_accuracy: 0.8411\n",
            "Epoch 297/1000\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0833 - accuracy: 0.9300 - val_loss: 0.1552 - val_accuracy: 0.8477\n",
            "Epoch 298/1000\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.0830 - accuracy: 0.9300 - val_loss: 0.1558 - val_accuracy: 0.8411\n",
            "Epoch 299/1000\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0831 - accuracy: 0.9250 - val_loss: 0.1571 - val_accuracy: 0.8344\n",
            "Epoch 300/1000\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0821 - accuracy: 0.9250 - val_loss: 0.1571 - val_accuracy: 0.8344\n",
            "Epoch 301/1000\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0826 - accuracy: 0.9300 - val_loss: 0.1572 - val_accuracy: 0.8344\n",
            "Epoch 302/1000\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0824 - accuracy: 0.9250 - val_loss: 0.1569 - val_accuracy: 0.8344\n",
            "Epoch 303/1000\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0821 - accuracy: 0.9250 - val_loss: 0.1567 - val_accuracy: 0.8344\n",
            "Epoch 304/1000\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0824 - accuracy: 0.9300 - val_loss: 0.1564 - val_accuracy: 0.8278\n",
            "Epoch 305/1000\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0827 - accuracy: 0.9200 - val_loss: 0.1564 - val_accuracy: 0.8278\n",
            "Epoch 306/1000\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0826 - accuracy: 0.9250 - val_loss: 0.1553 - val_accuracy: 0.8278\n",
            "Epoch 307/1000\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0825 - accuracy: 0.9300 - val_loss: 0.1550 - val_accuracy: 0.8212\n",
            "Epoch 308/1000\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.0830 - accuracy: 0.9300 - val_loss: 0.1538 - val_accuracy: 0.8344\n",
            "Epoch 309/1000\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0836 - accuracy: 0.9200 - val_loss: 0.1541 - val_accuracy: 0.8344\n",
            "Epoch 310/1000\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0830 - accuracy: 0.9250 - val_loss: 0.1561 - val_accuracy: 0.8344\n",
            "Epoch 311/1000\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.0830 - accuracy: 0.9350 - val_loss: 0.1581 - val_accuracy: 0.8212\n",
            "Epoch 312/1000\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.0824 - accuracy: 0.9300 - val_loss: 0.1581 - val_accuracy: 0.8344\n",
            "Epoch 313/1000\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0843 - accuracy: 0.9150 - val_loss: 0.1585 - val_accuracy: 0.8278\n",
            "Epoch 314/1000\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.0836 - accuracy: 0.9250 - val_loss: 0.1589 - val_accuracy: 0.8212\n",
            "Epoch 315/1000\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0831 - accuracy: 0.9300 - val_loss: 0.1572 - val_accuracy: 0.8344\n",
            "Epoch 316/1000\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0828 - accuracy: 0.9250 - val_loss: 0.1576 - val_accuracy: 0.8344\n",
            "Epoch 317/1000\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0821 - accuracy: 0.9300 - val_loss: 0.1576 - val_accuracy: 0.8344\n",
            "Epoch 318/1000\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0821 - accuracy: 0.9300 - val_loss: 0.1586 - val_accuracy: 0.8344\n",
            "Epoch 319/1000\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.0828 - accuracy: 0.9300 - val_loss: 0.1594 - val_accuracy: 0.8344\n",
            "Epoch 320/1000\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0830 - accuracy: 0.9250 - val_loss: 0.1590 - val_accuracy: 0.8411\n",
            "Epoch 321/1000\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0837 - accuracy: 0.9200 - val_loss: 0.1589 - val_accuracy: 0.8411\n",
            "Epoch 322/1000\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.0838 - accuracy: 0.9300 - val_loss: 0.1599 - val_accuracy: 0.8278\n",
            "Epoch 323/1000\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0826 - accuracy: 0.9350 - val_loss: 0.1589 - val_accuracy: 0.8344\n",
            "Epoch 324/1000\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0829 - accuracy: 0.9250 - val_loss: 0.1594 - val_accuracy: 0.8278\n",
            "Epoch 325/1000\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0821 - accuracy: 0.9250 - val_loss: 0.1579 - val_accuracy: 0.8278\n",
            "Epoch 326/1000\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.0839 - accuracy: 0.9350 - val_loss: 0.1579 - val_accuracy: 0.8212\n",
            "Epoch 327/1000\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.0832 - accuracy: 0.9150 - val_loss: 0.1591 - val_accuracy: 0.8278\n",
            "Epoch 328/1000\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0835 - accuracy: 0.9200 - val_loss: 0.1571 - val_accuracy: 0.8212\n",
            "Epoch 329/1000\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0833 - accuracy: 0.9300 - val_loss: 0.1573 - val_accuracy: 0.8212\n",
            "Epoch 330/1000\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.0822 - accuracy: 0.9300 - val_loss: 0.1592 - val_accuracy: 0.8278\n",
            "Epoch 331/1000\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0822 - accuracy: 0.9300 - val_loss: 0.1600 - val_accuracy: 0.8212\n",
            "Epoch 332/1000\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0827 - accuracy: 0.9200 - val_loss: 0.1600 - val_accuracy: 0.8278\n",
            "Epoch 333/1000\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0825 - accuracy: 0.9300 - val_loss: 0.1596 - val_accuracy: 0.8278\n",
            "Epoch 334/1000\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0826 - accuracy: 0.9300 - val_loss: 0.1601 - val_accuracy: 0.8278\n",
            "Epoch 335/1000\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0833 - accuracy: 0.9250 - val_loss: 0.1608 - val_accuracy: 0.8344\n",
            "Epoch 336/1000\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0835 - accuracy: 0.9150 - val_loss: 0.1593 - val_accuracy: 0.8344\n",
            "Epoch 337/1000\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0826 - accuracy: 0.9250 - val_loss: 0.1584 - val_accuracy: 0.8212\n",
            "Epoch 338/1000\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0832 - accuracy: 0.9250 - val_loss: 0.1589 - val_accuracy: 0.8278\n",
            "Epoch 339/1000\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0828 - accuracy: 0.9200 - val_loss: 0.1603 - val_accuracy: 0.8278\n",
            "Epoch 340/1000\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.0825 - accuracy: 0.9200 - val_loss: 0.1620 - val_accuracy: 0.8212\n",
            "Epoch 341/1000\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0825 - accuracy: 0.9300 - val_loss: 0.1628 - val_accuracy: 0.8278\n",
            "Epoch 342/1000\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.0826 - accuracy: 0.9300 - val_loss: 0.1617 - val_accuracy: 0.8344\n",
            "Epoch 343/1000\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0824 - accuracy: 0.9300 - val_loss: 0.1617 - val_accuracy: 0.8411\n",
            "Epoch 344/1000\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0837 - accuracy: 0.9250 - val_loss: 0.1619 - val_accuracy: 0.8411\n",
            "Epoch 345/1000\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0822 - accuracy: 0.9250 - val_loss: 0.1619 - val_accuracy: 0.8344\n",
            "Epoch 346/1000\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0822 - accuracy: 0.9300 - val_loss: 0.1617 - val_accuracy: 0.8411\n",
            "Epoch 347/1000\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.0821 - accuracy: 0.9200 - val_loss: 0.1617 - val_accuracy: 0.8411\n",
            "Epoch 348/1000\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.0821 - accuracy: 0.9300 - val_loss: 0.1630 - val_accuracy: 0.8411\n",
            "Epoch 349/1000\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.0826 - accuracy: 0.9250 - val_loss: 0.1620 - val_accuracy: 0.8344\n",
            "Epoch 350/1000\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0824 - accuracy: 0.9200 - val_loss: 0.1623 - val_accuracy: 0.8344\n",
            "Epoch 351/1000\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0827 - accuracy: 0.9200 - val_loss: 0.1635 - val_accuracy: 0.8278\n",
            "Epoch 352/1000\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0836 - accuracy: 0.9350 - val_loss: 0.1649 - val_accuracy: 0.8079\n",
            "Epoch 353/1000\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0834 - accuracy: 0.9350 - val_loss: 0.1645 - val_accuracy: 0.8344\n",
            "Epoch 354/1000\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0825 - accuracy: 0.9200 - val_loss: 0.1640 - val_accuracy: 0.8278\n",
            "Epoch 355/1000\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0822 - accuracy: 0.9300 - val_loss: 0.1648 - val_accuracy: 0.8212\n",
            "Epoch 356/1000\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0826 - accuracy: 0.9300 - val_loss: 0.1665 - val_accuracy: 0.8212\n",
            "Epoch 357/1000\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0829 - accuracy: 0.9300 - val_loss: 0.1666 - val_accuracy: 0.8212\n",
            "Epoch 358/1000\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0847 - accuracy: 0.9250 - val_loss: 0.1661 - val_accuracy: 0.8278\n",
            "Epoch 359/1000\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0825 - accuracy: 0.9300 - val_loss: 0.1645 - val_accuracy: 0.8212\n",
            "Epoch 360/1000\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0824 - accuracy: 0.9350 - val_loss: 0.1631 - val_accuracy: 0.8212\n",
            "Epoch 361/1000\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0826 - accuracy: 0.9200 - val_loss: 0.1631 - val_accuracy: 0.8212\n",
            "Epoch 362/1000\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0813 - accuracy: 0.9250 - val_loss: 0.1622 - val_accuracy: 0.8212\n",
            "Epoch 363/1000\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0830 - accuracy: 0.9350 - val_loss: 0.1630 - val_accuracy: 0.8212\n",
            "Epoch 364/1000\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0825 - accuracy: 0.9300 - val_loss: 0.1628 - val_accuracy: 0.8278\n",
            "Epoch 365/1000\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.0828 - accuracy: 0.9250 - val_loss: 0.1640 - val_accuracy: 0.8344\n",
            "Epoch 366/1000\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0823 - accuracy: 0.9250 - val_loss: 0.1641 - val_accuracy: 0.8212\n",
            "Epoch 367/1000\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0821 - accuracy: 0.9200 - val_loss: 0.1644 - val_accuracy: 0.8212\n",
            "Epoch 368/1000\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0818 - accuracy: 0.9250 - val_loss: 0.1656 - val_accuracy: 0.8146\n",
            "Epoch 369/1000\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0823 - accuracy: 0.9250 - val_loss: 0.1660 - val_accuracy: 0.8146\n",
            "Epoch 370/1000\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0821 - accuracy: 0.9300 - val_loss: 0.1662 - val_accuracy: 0.8278\n",
            "Epoch 371/1000\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0824 - accuracy: 0.9250 - val_loss: 0.1644 - val_accuracy: 0.8344\n",
            "Epoch 372/1000\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0821 - accuracy: 0.9250 - val_loss: 0.1638 - val_accuracy: 0.8411\n",
            "Epoch 373/1000\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0833 - accuracy: 0.9250 - val_loss: 0.1639 - val_accuracy: 0.8278\n",
            "Epoch 374/1000\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0824 - accuracy: 0.9250 - val_loss: 0.1632 - val_accuracy: 0.8411\n",
            "Epoch 375/1000\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0831 - accuracy: 0.9350 - val_loss: 0.1642 - val_accuracy: 0.8344\n",
            "Epoch 376/1000\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0829 - accuracy: 0.9300 - val_loss: 0.1634 - val_accuracy: 0.8278\n",
            "Epoch 377/1000\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0825 - accuracy: 0.9250 - val_loss: 0.1628 - val_accuracy: 0.8278\n",
            "Epoch 378/1000\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0818 - accuracy: 0.9350 - val_loss: 0.1633 - val_accuracy: 0.8278\n",
            "Epoch 379/1000\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.0820 - accuracy: 0.9350 - val_loss: 0.1631 - val_accuracy: 0.8278\n",
            "Epoch 380/1000\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0830 - accuracy: 0.9350 - val_loss: 0.1630 - val_accuracy: 0.8344\n",
            "Epoch 381/1000\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0820 - accuracy: 0.9300 - val_loss: 0.1636 - val_accuracy: 0.8411\n",
            "Epoch 382/1000\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0819 - accuracy: 0.9250 - val_loss: 0.1644 - val_accuracy: 0.8344\n",
            "Epoch 383/1000\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.0821 - accuracy: 0.9300 - val_loss: 0.1650 - val_accuracy: 0.8344\n",
            "Epoch 384/1000\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.0826 - accuracy: 0.9300 - val_loss: 0.1647 - val_accuracy: 0.8344\n",
            "Epoch 385/1000\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0821 - accuracy: 0.9300 - val_loss: 0.1647 - val_accuracy: 0.8477\n",
            "Epoch 386/1000\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.0829 - accuracy: 0.9200 - val_loss: 0.1646 - val_accuracy: 0.8278\n",
            "Epoch 387/1000\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.0822 - accuracy: 0.9250 - val_loss: 0.1647 - val_accuracy: 0.8212\n",
            "Epoch 388/1000\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0824 - accuracy: 0.9350 - val_loss: 0.1657 - val_accuracy: 0.8278\n",
            "Epoch 389/1000\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.0833 - accuracy: 0.9300 - val_loss: 0.1651 - val_accuracy: 0.8344\n",
            "Epoch 390/1000\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0827 - accuracy: 0.9200 - val_loss: 0.1653 - val_accuracy: 0.8278\n",
            "Epoch 391/1000\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.0824 - accuracy: 0.9300 - val_loss: 0.1685 - val_accuracy: 0.8212\n",
            "Epoch 392/1000\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0834 - accuracy: 0.9250 - val_loss: 0.1700 - val_accuracy: 0.8079\n",
            "Epoch 393/1000\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0829 - accuracy: 0.9300 - val_loss: 0.1696 - val_accuracy: 0.8146\n",
            "Epoch 394/1000\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0835 - accuracy: 0.9300 - val_loss: 0.1696 - val_accuracy: 0.8212\n",
            "Epoch 395/1000\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0820 - accuracy: 0.9250 - val_loss: 0.1672 - val_accuracy: 0.8344\n",
            "Epoch 396/1000\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0833 - accuracy: 0.9100 - val_loss: 0.1665 - val_accuracy: 0.8212\n",
            "Epoch 397/1000\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0832 - accuracy: 0.9250 - val_loss: 0.1665 - val_accuracy: 0.8146\n",
            "Epoch 398/1000\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0817 - accuracy: 0.9300 - val_loss: 0.1667 - val_accuracy: 0.8212\n",
            "Epoch 399/1000\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0828 - accuracy: 0.9150 - val_loss: 0.1666 - val_accuracy: 0.8212\n",
            "Epoch 400/1000\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0832 - accuracy: 0.9150 - val_loss: 0.1663 - val_accuracy: 0.8344\n",
            "Epoch 401/1000\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0840 - accuracy: 0.9300 - val_loss: 0.1686 - val_accuracy: 0.8344\n",
            "Epoch 402/1000\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0836 - accuracy: 0.9250 - val_loss: 0.1673 - val_accuracy: 0.8278\n",
            "Epoch 403/1000\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.0826 - accuracy: 0.9200 - val_loss: 0.1676 - val_accuracy: 0.8278\n",
            "Epoch 404/1000\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.0818 - accuracy: 0.9250 - val_loss: 0.1677 - val_accuracy: 0.8212\n",
            "Epoch 405/1000\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.0822 - accuracy: 0.9350 - val_loss: 0.1674 - val_accuracy: 0.8212\n",
            "Epoch 406/1000\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0818 - accuracy: 0.9300 - val_loss: 0.1672 - val_accuracy: 0.8278\n",
            "Epoch 407/1000\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0829 - accuracy: 0.9200 - val_loss: 0.1674 - val_accuracy: 0.8278\n",
            "Epoch 408/1000\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0829 - accuracy: 0.9200 - val_loss: 0.1682 - val_accuracy: 0.8278\n",
            "Epoch 409/1000\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0832 - accuracy: 0.9300 - val_loss: 0.1660 - val_accuracy: 0.8278\n",
            "Epoch 410/1000\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0829 - accuracy: 0.9200 - val_loss: 0.1666 - val_accuracy: 0.8411\n",
            "Epoch 411/1000\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0821 - accuracy: 0.9200 - val_loss: 0.1662 - val_accuracy: 0.8344\n",
            "Epoch 412/1000\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0837 - accuracy: 0.9300 - val_loss: 0.1655 - val_accuracy: 0.8278\n",
            "Epoch 413/1000\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.0827 - accuracy: 0.9200 - val_loss: 0.1671 - val_accuracy: 0.8278\n",
            "Epoch 414/1000\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.0832 - accuracy: 0.9200 - val_loss: 0.1650 - val_accuracy: 0.8212\n",
            "Epoch 415/1000\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0821 - accuracy: 0.9200 - val_loss: 0.1643 - val_accuracy: 0.8146\n",
            "Epoch 416/1000\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0826 - accuracy: 0.9200 - val_loss: 0.1634 - val_accuracy: 0.8344\n",
            "Epoch 417/1000\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.0833 - accuracy: 0.9250 - val_loss: 0.1637 - val_accuracy: 0.8344\n",
            "Epoch 418/1000\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0836 - accuracy: 0.9200 - val_loss: 0.1635 - val_accuracy: 0.8344\n",
            "Epoch 419/1000\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0820 - accuracy: 0.9300 - val_loss: 0.1654 - val_accuracy: 0.8212\n",
            "Epoch 420/1000\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.0822 - accuracy: 0.9250 - val_loss: 0.1647 - val_accuracy: 0.8146\n",
            "Epoch 421/1000\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.0829 - accuracy: 0.9350 - val_loss: 0.1634 - val_accuracy: 0.8278\n",
            "Epoch 422/1000\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.0827 - accuracy: 0.9250 - val_loss: 0.1630 - val_accuracy: 0.8411\n",
            "Epoch 423/1000\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.0833 - accuracy: 0.9250 - val_loss: 0.1636 - val_accuracy: 0.8344\n",
            "Epoch 424/1000\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0824 - accuracy: 0.9350 - val_loss: 0.1639 - val_accuracy: 0.8146\n",
            "Epoch 425/1000\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0820 - accuracy: 0.9300 - val_loss: 0.1635 - val_accuracy: 0.8212\n",
            "Epoch 426/1000\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0819 - accuracy: 0.9250 - val_loss: 0.1633 - val_accuracy: 0.8212\n",
            "Epoch 427/1000\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0821 - accuracy: 0.9300 - val_loss: 0.1628 - val_accuracy: 0.8278\n",
            "Epoch 428/1000\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.0829 - accuracy: 0.9250 - val_loss: 0.1623 - val_accuracy: 0.8212\n",
            "Epoch 429/1000\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0827 - accuracy: 0.9350 - val_loss: 0.1633 - val_accuracy: 0.8212\n",
            "Epoch 430/1000\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0837 - accuracy: 0.9350 - val_loss: 0.1649 - val_accuracy: 0.8212\n",
            "Epoch 431/1000\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0829 - accuracy: 0.9350 - val_loss: 0.1639 - val_accuracy: 0.8278\n",
            "Epoch 432/1000\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.0837 - accuracy: 0.9250 - val_loss: 0.1645 - val_accuracy: 0.8344\n",
            "Epoch 433/1000\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.0830 - accuracy: 0.9200 - val_loss: 0.1648 - val_accuracy: 0.8212\n",
            "Epoch 434/1000\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0820 - accuracy: 0.9300 - val_loss: 0.1646 - val_accuracy: 0.8278\n",
            "Epoch 435/1000\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0825 - accuracy: 0.9300 - val_loss: 0.1655 - val_accuracy: 0.8344\n",
            "Epoch 436/1000\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.0820 - accuracy: 0.9250 - val_loss: 0.1658 - val_accuracy: 0.8344\n",
            "Epoch 437/1000\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0827 - accuracy: 0.9250 - val_loss: 0.1659 - val_accuracy: 0.8278\n",
            "Epoch 438/1000\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0825 - accuracy: 0.9250 - val_loss: 0.1657 - val_accuracy: 0.8411\n",
            "Epoch 439/1000\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0830 - accuracy: 0.9250 - val_loss: 0.1651 - val_accuracy: 0.8344\n",
            "Epoch 440/1000\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0818 - accuracy: 0.9250 - val_loss: 0.1651 - val_accuracy: 0.8344\n",
            "Epoch 441/1000\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.0824 - accuracy: 0.9300 - val_loss: 0.1661 - val_accuracy: 0.8278\n",
            "Epoch 442/1000\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0816 - accuracy: 0.9350 - val_loss: 0.1650 - val_accuracy: 0.8146\n",
            "Epoch 443/1000\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0827 - accuracy: 0.9200 - val_loss: 0.1647 - val_accuracy: 0.8212\n",
            "Epoch 444/1000\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0821 - accuracy: 0.9250 - val_loss: 0.1636 - val_accuracy: 0.8146\n",
            "Epoch 445/1000\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.0822 - accuracy: 0.9300 - val_loss: 0.1652 - val_accuracy: 0.8212\n",
            "Epoch 446/1000\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0850 - accuracy: 0.9350 - val_loss: 0.1696 - val_accuracy: 0.8079\n",
            "Epoch 447/1000\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0837 - accuracy: 0.9250 - val_loss: 0.1680 - val_accuracy: 0.8278\n",
            "Epoch 448/1000\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0835 - accuracy: 0.9200 - val_loss: 0.1677 - val_accuracy: 0.8344\n",
            "Epoch 449/1000\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.0833 - accuracy: 0.9200 - val_loss: 0.1675 - val_accuracy: 0.8344\n",
            "Epoch 450/1000\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.0833 - accuracy: 0.9300 - val_loss: 0.1688 - val_accuracy: 0.8344\n",
            "Epoch 451/1000\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0823 - accuracy: 0.9300 - val_loss: 0.1679 - val_accuracy: 0.8344\n",
            "Epoch 452/1000\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0826 - accuracy: 0.9200 - val_loss: 0.1692 - val_accuracy: 0.8212\n",
            "Epoch 453/1000\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0824 - accuracy: 0.9250 - val_loss: 0.1675 - val_accuracy: 0.8212\n",
            "Epoch 454/1000\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0835 - accuracy: 0.9250 - val_loss: 0.1670 - val_accuracy: 0.8212\n",
            "Epoch 455/1000\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.0828 - accuracy: 0.9250 - val_loss: 0.1685 - val_accuracy: 0.8146\n",
            "Epoch 456/1000\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0825 - accuracy: 0.9250 - val_loss: 0.1680 - val_accuracy: 0.8146\n",
            "Epoch 457/1000\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0835 - accuracy: 0.9200 - val_loss: 0.1686 - val_accuracy: 0.8146\n",
            "Epoch 458/1000\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.0834 - accuracy: 0.9100 - val_loss: 0.1683 - val_accuracy: 0.8079\n",
            "Epoch 459/1000\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0830 - accuracy: 0.9200 - val_loss: 0.1684 - val_accuracy: 0.8212\n",
            "Epoch 460/1000\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0831 - accuracy: 0.9350 - val_loss: 0.1687 - val_accuracy: 0.8212\n",
            "Epoch 461/1000\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0822 - accuracy: 0.9250 - val_loss: 0.1678 - val_accuracy: 0.8278\n",
            "Epoch 462/1000\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0825 - accuracy: 0.9200 - val_loss: 0.1680 - val_accuracy: 0.8278\n",
            "Epoch 463/1000\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0820 - accuracy: 0.9300 - val_loss: 0.1694 - val_accuracy: 0.8146\n",
            "Epoch 464/1000\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0823 - accuracy: 0.9350 - val_loss: 0.1673 - val_accuracy: 0.8079\n",
            "Epoch 465/1000\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0871 - accuracy: 0.9050 - val_loss: 0.1688 - val_accuracy: 0.8146\n",
            "Epoch 466/1000\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0840 - accuracy: 0.9150 - val_loss: 0.1679 - val_accuracy: 0.8212\n",
            "Epoch 467/1000\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0841 - accuracy: 0.9300 - val_loss: 0.1668 - val_accuracy: 0.8278\n",
            "Epoch 468/1000\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0824 - accuracy: 0.9300 - val_loss: 0.1688 - val_accuracy: 0.8278\n",
            "Epoch 469/1000\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.0826 - accuracy: 0.9250 - val_loss: 0.1703 - val_accuracy: 0.8212\n",
            "Epoch 470/1000\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0836 - accuracy: 0.9350 - val_loss: 0.1696 - val_accuracy: 0.8079\n",
            "Epoch 471/1000\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0830 - accuracy: 0.9250 - val_loss: 0.1678 - val_accuracy: 0.8212\n",
            "Epoch 472/1000\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0827 - accuracy: 0.9200 - val_loss: 0.1681 - val_accuracy: 0.8212\n",
            "Epoch 473/1000\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.0825 - accuracy: 0.9300 - val_loss: 0.1681 - val_accuracy: 0.8146\n",
            "Epoch 474/1000\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.0842 - accuracy: 0.9350 - val_loss: 0.1673 - val_accuracy: 0.8212\n",
            "Epoch 475/1000\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0819 - accuracy: 0.9250 - val_loss: 0.1664 - val_accuracy: 0.8278\n",
            "Epoch 476/1000\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0835 - accuracy: 0.9200 - val_loss: 0.1659 - val_accuracy: 0.8212\n",
            "Epoch 477/1000\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0821 - accuracy: 0.9250 - val_loss: 0.1666 - val_accuracy: 0.8212\n",
            "Epoch 478/1000\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0825 - accuracy: 0.9350 - val_loss: 0.1681 - val_accuracy: 0.8146\n",
            "Epoch 479/1000\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.0826 - accuracy: 0.9300 - val_loss: 0.1685 - val_accuracy: 0.8212\n",
            "Epoch 480/1000\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0822 - accuracy: 0.9250 - val_loss: 0.1684 - val_accuracy: 0.8278\n",
            "Epoch 481/1000\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0821 - accuracy: 0.9300 - val_loss: 0.1689 - val_accuracy: 0.8278\n",
            "Epoch 482/1000\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0831 - accuracy: 0.9300 - val_loss: 0.1688 - val_accuracy: 0.8212\n",
            "Epoch 483/1000\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0819 - accuracy: 0.9300 - val_loss: 0.1698 - val_accuracy: 0.8212\n",
            "Epoch 484/1000\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.0835 - accuracy: 0.9250 - val_loss: 0.1689 - val_accuracy: 0.8212\n",
            "Epoch 485/1000\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0822 - accuracy: 0.9200 - val_loss: 0.1687 - val_accuracy: 0.8212\n",
            "Epoch 486/1000\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.0829 - accuracy: 0.9200 - val_loss: 0.1687 - val_accuracy: 0.8212\n",
            "Epoch 487/1000\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0818 - accuracy: 0.9250 - val_loss: 0.1695 - val_accuracy: 0.8212\n",
            "Epoch 488/1000\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.0826 - accuracy: 0.9350 - val_loss: 0.1671 - val_accuracy: 0.8212\n",
            "Epoch 489/1000\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0824 - accuracy: 0.9350 - val_loss: 0.1667 - val_accuracy: 0.8212\n",
            "Epoch 490/1000\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.0821 - accuracy: 0.9300 - val_loss: 0.1670 - val_accuracy: 0.8212\n",
            "Epoch 491/1000\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0835 - accuracy: 0.9250 - val_loss: 0.1682 - val_accuracy: 0.8079\n",
            "Epoch 492/1000\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0831 - accuracy: 0.9300 - val_loss: 0.1686 - val_accuracy: 0.8146\n",
            "Epoch 493/1000\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0827 - accuracy: 0.9250 - val_loss: 0.1681 - val_accuracy: 0.8344\n",
            "Epoch 494/1000\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0824 - accuracy: 0.9250 - val_loss: 0.1671 - val_accuracy: 0.8278\n",
            "Epoch 495/1000\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0821 - accuracy: 0.9200 - val_loss: 0.1670 - val_accuracy: 0.8212\n",
            "Epoch 496/1000\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0825 - accuracy: 0.9200 - val_loss: 0.1678 - val_accuracy: 0.8146\n",
            "Epoch 497/1000\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0818 - accuracy: 0.9250 - val_loss: 0.1687 - val_accuracy: 0.8079\n",
            "Epoch 498/1000\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0821 - accuracy: 0.9350 - val_loss: 0.1689 - val_accuracy: 0.8212\n",
            "Epoch 499/1000\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.0821 - accuracy: 0.9350 - val_loss: 0.1681 - val_accuracy: 0.8278\n",
            "Epoch 500/1000\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0822 - accuracy: 0.9250 - val_loss: 0.1665 - val_accuracy: 0.8146\n",
            "Epoch 501/1000\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.0820 - accuracy: 0.9200 - val_loss: 0.1662 - val_accuracy: 0.8212\n",
            "Epoch 502/1000\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.0830 - accuracy: 0.9300 - val_loss: 0.1677 - val_accuracy: 0.8146\n",
            "Epoch 503/1000\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0836 - accuracy: 0.9200 - val_loss: 0.1677 - val_accuracy: 0.8146\n",
            "Epoch 504/1000\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.0832 - accuracy: 0.9250 - val_loss: 0.1684 - val_accuracy: 0.8278\n",
            "Epoch 505/1000\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.0827 - accuracy: 0.9200 - val_loss: 0.1674 - val_accuracy: 0.8278\n",
            "Epoch 506/1000\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0827 - accuracy: 0.9350 - val_loss: 0.1682 - val_accuracy: 0.8212\n",
            "Epoch 507/1000\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0836 - accuracy: 0.9200 - val_loss: 0.1693 - val_accuracy: 0.8278\n",
            "Epoch 508/1000\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.0847 - accuracy: 0.9200 - val_loss: 0.1714 - val_accuracy: 0.8079\n",
            "Epoch 509/1000\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0862 - accuracy: 0.9350 - val_loss: 0.1714 - val_accuracy: 0.8146\n",
            "Epoch 510/1000\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.0831 - accuracy: 0.9250 - val_loss: 0.1694 - val_accuracy: 0.8278\n",
            "Epoch 511/1000\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0833 - accuracy: 0.9200 - val_loss: 0.1681 - val_accuracy: 0.8146\n",
            "Epoch 512/1000\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.0822 - accuracy: 0.9200 - val_loss: 0.1679 - val_accuracy: 0.8278\n",
            "Epoch 513/1000\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0826 - accuracy: 0.9300 - val_loss: 0.1671 - val_accuracy: 0.8278\n",
            "Epoch 514/1000\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.0832 - accuracy: 0.9350 - val_loss: 0.1689 - val_accuracy: 0.8212\n",
            "Epoch 515/1000\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0826 - accuracy: 0.9300 - val_loss: 0.1685 - val_accuracy: 0.8146\n",
            "Epoch 516/1000\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0828 - accuracy: 0.9200 - val_loss: 0.1680 - val_accuracy: 0.8212\n",
            "Epoch 517/1000\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.0820 - accuracy: 0.9250 - val_loss: 0.1675 - val_accuracy: 0.8146\n",
            "Epoch 518/1000\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.0823 - accuracy: 0.9250 - val_loss: 0.1667 - val_accuracy: 0.8212\n",
            "Epoch 519/1000\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0823 - accuracy: 0.9300 - val_loss: 0.1671 - val_accuracy: 0.8212\n",
            "Epoch 520/1000\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.0821 - accuracy: 0.9250 - val_loss: 0.1665 - val_accuracy: 0.8212\n",
            "Epoch 521/1000\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0833 - accuracy: 0.9300 - val_loss: 0.1674 - val_accuracy: 0.8079\n",
            "Epoch 522/1000\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0822 - accuracy: 0.9300 - val_loss: 0.1674 - val_accuracy: 0.8079\n",
            "Epoch 523/1000\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0827 - accuracy: 0.9200 - val_loss: 0.1678 - val_accuracy: 0.8212\n",
            "Epoch 524/1000\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0827 - accuracy: 0.9250 - val_loss: 0.1679 - val_accuracy: 0.8146\n",
            "Epoch 525/1000\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0823 - accuracy: 0.9250 - val_loss: 0.1686 - val_accuracy: 0.8079\n",
            "Epoch 526/1000\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0827 - accuracy: 0.9250 - val_loss: 0.1676 - val_accuracy: 0.8212\n",
            "Epoch 527/1000\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.0823 - accuracy: 0.9200 - val_loss: 0.1685 - val_accuracy: 0.8146\n",
            "Epoch 528/1000\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0820 - accuracy: 0.9300 - val_loss: 0.1695 - val_accuracy: 0.8013\n",
            "Epoch 529/1000\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0839 - accuracy: 0.9200 - val_loss: 0.1687 - val_accuracy: 0.8146\n",
            "Epoch 530/1000\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0824 - accuracy: 0.9200 - val_loss: 0.1693 - val_accuracy: 0.8278\n",
            "Epoch 531/1000\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0830 - accuracy: 0.9300 - val_loss: 0.1701 - val_accuracy: 0.8278\n",
            "Epoch 532/1000\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0819 - accuracy: 0.9200 - val_loss: 0.1699 - val_accuracy: 0.8278\n",
            "Epoch 533/1000\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0827 - accuracy: 0.9150 - val_loss: 0.1690 - val_accuracy: 0.8278\n",
            "Epoch 534/1000\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.0821 - accuracy: 0.9350 - val_loss: 0.1688 - val_accuracy: 0.8278\n",
            "Epoch 535/1000\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.0832 - accuracy: 0.9200 - val_loss: 0.1683 - val_accuracy: 0.8212\n",
            "Epoch 536/1000\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.0822 - accuracy: 0.9300 - val_loss: 0.1706 - val_accuracy: 0.8013\n",
            "Epoch 537/1000\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0830 - accuracy: 0.9300 - val_loss: 0.1688 - val_accuracy: 0.8146\n",
            "Epoch 538/1000\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0818 - accuracy: 0.9300 - val_loss: 0.1681 - val_accuracy: 0.8212\n",
            "Epoch 539/1000\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0829 - accuracy: 0.9200 - val_loss: 0.1674 - val_accuracy: 0.8146\n",
            "Epoch 540/1000\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.0840 - accuracy: 0.9250 - val_loss: 0.1674 - val_accuracy: 0.8146\n",
            "Epoch 541/1000\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.0820 - accuracy: 0.9300 - val_loss: 0.1675 - val_accuracy: 0.8212\n",
            "Epoch 542/1000\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0822 - accuracy: 0.9200 - val_loss: 0.1681 - val_accuracy: 0.8212\n",
            "Epoch 543/1000\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0834 - accuracy: 0.9150 - val_loss: 0.1677 - val_accuracy: 0.8146\n",
            "Epoch 544/1000\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0833 - accuracy: 0.9250 - val_loss: 0.1669 - val_accuracy: 0.8278\n",
            "Epoch 545/1000\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0827 - accuracy: 0.9300 - val_loss: 0.1660 - val_accuracy: 0.8212\n",
            "Epoch 546/1000\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0836 - accuracy: 0.9300 - val_loss: 0.1662 - val_accuracy: 0.8212\n",
            "Epoch 547/1000\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.0822 - accuracy: 0.9250 - val_loss: 0.1663 - val_accuracy: 0.8212\n",
            "Epoch 548/1000\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0836 - accuracy: 0.9150 - val_loss: 0.1668 - val_accuracy: 0.8212\n",
            "Epoch 549/1000\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.0826 - accuracy: 0.9200 - val_loss: 0.1689 - val_accuracy: 0.8212\n",
            "Epoch 550/1000\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.0828 - accuracy: 0.9300 - val_loss: 0.1692 - val_accuracy: 0.8278\n",
            "Epoch 551/1000\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0830 - accuracy: 0.9250 - val_loss: 0.1688 - val_accuracy: 0.8212\n",
            "Epoch 552/1000\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0830 - accuracy: 0.9200 - val_loss: 0.1691 - val_accuracy: 0.8278\n",
            "Epoch 553/1000\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.0828 - accuracy: 0.9300 - val_loss: 0.1711 - val_accuracy: 0.8146\n",
            "Epoch 554/1000\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0832 - accuracy: 0.9300 - val_loss: 0.1691 - val_accuracy: 0.8212\n",
            "Epoch 555/1000\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0827 - accuracy: 0.9150 - val_loss: 0.1700 - val_accuracy: 0.8079\n",
            "Epoch 556/1000\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0835 - accuracy: 0.9150 - val_loss: 0.1676 - val_accuracy: 0.8212\n",
            "Epoch 557/1000\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0825 - accuracy: 0.9250 - val_loss: 0.1674 - val_accuracy: 0.8212\n",
            "Epoch 558/1000\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0822 - accuracy: 0.9300 - val_loss: 0.1675 - val_accuracy: 0.8278\n",
            "Epoch 559/1000\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0824 - accuracy: 0.9350 - val_loss: 0.1665 - val_accuracy: 0.8278\n",
            "Epoch 560/1000\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.0822 - accuracy: 0.9200 - val_loss: 0.1652 - val_accuracy: 0.8411\n",
            "Epoch 561/1000\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0831 - accuracy: 0.9250 - val_loss: 0.1642 - val_accuracy: 0.8344\n",
            "Epoch 562/1000\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0833 - accuracy: 0.9200 - val_loss: 0.1651 - val_accuracy: 0.8344\n",
            "Epoch 563/1000\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0828 - accuracy: 0.9200 - val_loss: 0.1658 - val_accuracy: 0.8344\n",
            "Epoch 564/1000\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0827 - accuracy: 0.9300 - val_loss: 0.1665 - val_accuracy: 0.8146\n",
            "Epoch 565/1000\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.0828 - accuracy: 0.9300 - val_loss: 0.1671 - val_accuracy: 0.8212\n",
            "Epoch 566/1000\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0834 - accuracy: 0.9350 - val_loss: 0.1645 - val_accuracy: 0.8278\n",
            "Epoch 567/1000\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0844 - accuracy: 0.9250 - val_loss: 0.1649 - val_accuracy: 0.8212\n",
            "Epoch 568/1000\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.0832 - accuracy: 0.9300 - val_loss: 0.1654 - val_accuracy: 0.8146\n",
            "Epoch 569/1000\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.0825 - accuracy: 0.9250 - val_loss: 0.1663 - val_accuracy: 0.8212\n",
            "Epoch 570/1000\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.0824 - accuracy: 0.9250 - val_loss: 0.1669 - val_accuracy: 0.8212\n",
            "Epoch 571/1000\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.0826 - accuracy: 0.9250 - val_loss: 0.1668 - val_accuracy: 0.8344\n",
            "Epoch 572/1000\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0834 - accuracy: 0.9250 - val_loss: 0.1670 - val_accuracy: 0.8411\n",
            "Epoch 573/1000\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0823 - accuracy: 0.9250 - val_loss: 0.1678 - val_accuracy: 0.8278\n",
            "Epoch 574/1000\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0835 - accuracy: 0.9350 - val_loss: 0.1667 - val_accuracy: 0.8344\n",
            "Epoch 575/1000\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0825 - accuracy: 0.9350 - val_loss: 0.1672 - val_accuracy: 0.8344\n",
            "Epoch 576/1000\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0830 - accuracy: 0.9200 - val_loss: 0.1671 - val_accuracy: 0.8411\n",
            "Epoch 577/1000\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0823 - accuracy: 0.9200 - val_loss: 0.1672 - val_accuracy: 0.8278\n",
            "Epoch 578/1000\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.0824 - accuracy: 0.9200 - val_loss: 0.1669 - val_accuracy: 0.8212\n",
            "Epoch 579/1000\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0821 - accuracy: 0.9200 - val_loss: 0.1666 - val_accuracy: 0.8212\n",
            "Epoch 580/1000\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.0819 - accuracy: 0.9250 - val_loss: 0.1665 - val_accuracy: 0.8344\n",
            "Epoch 581/1000\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0828 - accuracy: 0.9300 - val_loss: 0.1682 - val_accuracy: 0.8344\n",
            "Epoch 582/1000\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.0833 - accuracy: 0.9250 - val_loss: 0.1672 - val_accuracy: 0.8411\n",
            "Epoch 583/1000\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0827 - accuracy: 0.9250 - val_loss: 0.1673 - val_accuracy: 0.8344\n",
            "Epoch 584/1000\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.0821 - accuracy: 0.9250 - val_loss: 0.1654 - val_accuracy: 0.8278\n",
            "Epoch 585/1000\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0823 - accuracy: 0.9300 - val_loss: 0.1646 - val_accuracy: 0.8344\n",
            "Epoch 586/1000\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0817 - accuracy: 0.9300 - val_loss: 0.1666 - val_accuracy: 0.8278\n",
            "Epoch 587/1000\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0821 - accuracy: 0.9350 - val_loss: 0.1683 - val_accuracy: 0.8344\n",
            "Epoch 588/1000\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0822 - accuracy: 0.9300 - val_loss: 0.1694 - val_accuracy: 0.8344\n",
            "Epoch 589/1000\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0827 - accuracy: 0.9300 - val_loss: 0.1686 - val_accuracy: 0.8344\n",
            "Epoch 590/1000\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0825 - accuracy: 0.9350 - val_loss: 0.1685 - val_accuracy: 0.8146\n",
            "Epoch 591/1000\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.0830 - accuracy: 0.9350 - val_loss: 0.1695 - val_accuracy: 0.8146\n",
            "Epoch 592/1000\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0819 - accuracy: 0.9300 - val_loss: 0.1687 - val_accuracy: 0.8212\n",
            "Epoch 593/1000\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0825 - accuracy: 0.9300 - val_loss: 0.1674 - val_accuracy: 0.8278\n",
            "Epoch 594/1000\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0818 - accuracy: 0.9250 - val_loss: 0.1657 - val_accuracy: 0.8278\n",
            "Epoch 595/1000\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0833 - accuracy: 0.9200 - val_loss: 0.1655 - val_accuracy: 0.8212\n",
            "Epoch 596/1000\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0824 - accuracy: 0.9200 - val_loss: 0.1659 - val_accuracy: 0.8212\n",
            "Epoch 597/1000\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0826 - accuracy: 0.9350 - val_loss: 0.1675 - val_accuracy: 0.8146\n",
            "Epoch 598/1000\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0825 - accuracy: 0.9250 - val_loss: 0.1657 - val_accuracy: 0.8212\n",
            "Epoch 599/1000\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0821 - accuracy: 0.9300 - val_loss: 0.1654 - val_accuracy: 0.8146\n",
            "Epoch 600/1000\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.0828 - accuracy: 0.9250 - val_loss: 0.1657 - val_accuracy: 0.8146\n",
            "Epoch 601/1000\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0826 - accuracy: 0.9300 - val_loss: 0.1653 - val_accuracy: 0.8212\n",
            "Epoch 602/1000\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.0833 - accuracy: 0.9300 - val_loss: 0.1655 - val_accuracy: 0.8278\n",
            "Epoch 603/1000\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0828 - accuracy: 0.9200 - val_loss: 0.1651 - val_accuracy: 0.8212\n",
            "Epoch 604/1000\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0823 - accuracy: 0.9350 - val_loss: 0.1650 - val_accuracy: 0.8278\n",
            "Epoch 605/1000\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0821 - accuracy: 0.9300 - val_loss: 0.1669 - val_accuracy: 0.8278\n",
            "Epoch 606/1000\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0824 - accuracy: 0.9200 - val_loss: 0.1680 - val_accuracy: 0.8278\n",
            "Epoch 607/1000\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.0822 - accuracy: 0.9250 - val_loss: 0.1682 - val_accuracy: 0.8212\n",
            "Epoch 608/1000\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0838 - accuracy: 0.9300 - val_loss: 0.1681 - val_accuracy: 0.8146\n",
            "Epoch 609/1000\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0829 - accuracy: 0.9200 - val_loss: 0.1687 - val_accuracy: 0.8344\n",
            "Epoch 610/1000\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.0830 - accuracy: 0.9200 - val_loss: 0.1688 - val_accuracy: 0.8344\n",
            "Epoch 611/1000\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0829 - accuracy: 0.9250 - val_loss: 0.1687 - val_accuracy: 0.8344\n",
            "Epoch 612/1000\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0827 - accuracy: 0.9300 - val_loss: 0.1675 - val_accuracy: 0.8278\n",
            "Epoch 613/1000\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0824 - accuracy: 0.9250 - val_loss: 0.1657 - val_accuracy: 0.8411\n",
            "Epoch 614/1000\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0829 - accuracy: 0.9250 - val_loss: 0.1645 - val_accuracy: 0.8278\n",
            "Epoch 615/1000\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0820 - accuracy: 0.9200 - val_loss: 0.1662 - val_accuracy: 0.8212\n",
            "Epoch 616/1000\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.0823 - accuracy: 0.9200 - val_loss: 0.1672 - val_accuracy: 0.8212\n",
            "Epoch 617/1000\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0822 - accuracy: 0.9300 - val_loss: 0.1674 - val_accuracy: 0.8212\n",
            "Epoch 618/1000\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0823 - accuracy: 0.9250 - val_loss: 0.1664 - val_accuracy: 0.8278\n",
            "Epoch 619/1000\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.0826 - accuracy: 0.9200 - val_loss: 0.1662 - val_accuracy: 0.8278\n",
            "Epoch 620/1000\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0826 - accuracy: 0.9250 - val_loss: 0.1661 - val_accuracy: 0.8212\n",
            "Epoch 621/1000\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0830 - accuracy: 0.9300 - val_loss: 0.1667 - val_accuracy: 0.8146\n",
            "Epoch 622/1000\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.0834 - accuracy: 0.9300 - val_loss: 0.1667 - val_accuracy: 0.8212\n",
            "Epoch 623/1000\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0858 - accuracy: 0.9050 - val_loss: 0.1692 - val_accuracy: 0.8146\n",
            "Epoch 624/1000\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0835 - accuracy: 0.9050 - val_loss: 0.1697 - val_accuracy: 0.8146\n",
            "Epoch 625/1000\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.0839 - accuracy: 0.9250 - val_loss: 0.1722 - val_accuracy: 0.7947\n",
            "Epoch 626/1000\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0840 - accuracy: 0.9250 - val_loss: 0.1687 - val_accuracy: 0.8079\n",
            "Epoch 627/1000\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0822 - accuracy: 0.9250 - val_loss: 0.1679 - val_accuracy: 0.8212\n",
            "Epoch 628/1000\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.0829 - accuracy: 0.9200 - val_loss: 0.1675 - val_accuracy: 0.8146\n",
            "Epoch 629/1000\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0827 - accuracy: 0.9250 - val_loss: 0.1669 - val_accuracy: 0.8146\n",
            "Epoch 630/1000\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.0829 - accuracy: 0.9300 - val_loss: 0.1654 - val_accuracy: 0.8146\n",
            "Epoch 631/1000\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0826 - accuracy: 0.9200 - val_loss: 0.1667 - val_accuracy: 0.8212\n",
            "Epoch 632/1000\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0827 - accuracy: 0.9250 - val_loss: 0.1669 - val_accuracy: 0.8146\n",
            "Epoch 633/1000\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0826 - accuracy: 0.9300 - val_loss: 0.1675 - val_accuracy: 0.8146\n",
            "Epoch 634/1000\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.0818 - accuracy: 0.9250 - val_loss: 0.1687 - val_accuracy: 0.8212\n",
            "Epoch 635/1000\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.0828 - accuracy: 0.9250 - val_loss: 0.1686 - val_accuracy: 0.8146\n",
            "Epoch 636/1000\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0825 - accuracy: 0.9250 - val_loss: 0.1676 - val_accuracy: 0.8146\n",
            "Epoch 637/1000\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.0825 - accuracy: 0.9250 - val_loss: 0.1675 - val_accuracy: 0.8212\n",
            "Epoch 638/1000\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0816 - accuracy: 0.9250 - val_loss: 0.1670 - val_accuracy: 0.8278\n",
            "Epoch 639/1000\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0826 - accuracy: 0.9300 - val_loss: 0.1679 - val_accuracy: 0.8278\n",
            "Epoch 640/1000\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.0829 - accuracy: 0.9250 - val_loss: 0.1688 - val_accuracy: 0.8278\n",
            "Epoch 641/1000\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.0823 - accuracy: 0.9350 - val_loss: 0.1707 - val_accuracy: 0.8212\n",
            "Epoch 642/1000\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.0824 - accuracy: 0.9300 - val_loss: 0.1685 - val_accuracy: 0.8212\n",
            "Epoch 643/1000\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.0829 - accuracy: 0.9250 - val_loss: 0.1679 - val_accuracy: 0.8212\n",
            "Epoch 644/1000\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0834 - accuracy: 0.9150 - val_loss: 0.1667 - val_accuracy: 0.8146\n",
            "Epoch 645/1000\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0819 - accuracy: 0.9300 - val_loss: 0.1680 - val_accuracy: 0.8278\n",
            "Epoch 646/1000\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.0861 - accuracy: 0.9350 - val_loss: 0.1700 - val_accuracy: 0.8146\n",
            "Epoch 647/1000\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.0812 - accuracy: 0.9300 - val_loss: 0.1698 - val_accuracy: 0.8344\n",
            "Epoch 648/1000\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0872 - accuracy: 0.9000 - val_loss: 0.1698 - val_accuracy: 0.8278\n",
            "Epoch 649/1000\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0819 - accuracy: 0.9300 - val_loss: 0.1690 - val_accuracy: 0.8212\n",
            "Epoch 650/1000\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0856 - accuracy: 0.9350 - val_loss: 0.1667 - val_accuracy: 0.8146\n",
            "Epoch 651/1000\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.0842 - accuracy: 0.9350 - val_loss: 0.1654 - val_accuracy: 0.8146\n",
            "Epoch 652/1000\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0832 - accuracy: 0.9250 - val_loss: 0.1664 - val_accuracy: 0.8212\n",
            "Epoch 653/1000\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0828 - accuracy: 0.9200 - val_loss: 0.1682 - val_accuracy: 0.8212\n",
            "Epoch 654/1000\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0825 - accuracy: 0.9250 - val_loss: 0.1688 - val_accuracy: 0.8212\n",
            "Epoch 655/1000\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0828 - accuracy: 0.9350 - val_loss: 0.1685 - val_accuracy: 0.8146\n",
            "Epoch 656/1000\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.0824 - accuracy: 0.9250 - val_loss: 0.1688 - val_accuracy: 0.8212\n",
            "Epoch 657/1000\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.0836 - accuracy: 0.9150 - val_loss: 0.1689 - val_accuracy: 0.8278\n",
            "Epoch 658/1000\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0824 - accuracy: 0.9300 - val_loss: 0.1685 - val_accuracy: 0.8212\n",
            "Epoch 659/1000\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0829 - accuracy: 0.9350 - val_loss: 0.1685 - val_accuracy: 0.8212\n",
            "Epoch 660/1000\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.0824 - accuracy: 0.9350 - val_loss: 0.1686 - val_accuracy: 0.8278\n",
            "Epoch 661/1000\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0826 - accuracy: 0.9200 - val_loss: 0.1683 - val_accuracy: 0.8278\n",
            "Epoch 662/1000\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.0816 - accuracy: 0.9200 - val_loss: 0.1677 - val_accuracy: 0.8212\n",
            "Epoch 663/1000\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.0838 - accuracy: 0.9300 - val_loss: 0.1680 - val_accuracy: 0.8212\n",
            "Epoch 664/1000\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0829 - accuracy: 0.9300 - val_loss: 0.1671 - val_accuracy: 0.8278\n",
            "Epoch 665/1000\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0832 - accuracy: 0.9200 - val_loss: 0.1665 - val_accuracy: 0.8278\n",
            "Epoch 666/1000\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0829 - accuracy: 0.9350 - val_loss: 0.1698 - val_accuracy: 0.8212\n",
            "Epoch 667/1000\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.0835 - accuracy: 0.9350 - val_loss: 0.1688 - val_accuracy: 0.8278\n",
            "Epoch 668/1000\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.0827 - accuracy: 0.9300 - val_loss: 0.1680 - val_accuracy: 0.8278\n",
            "Epoch 669/1000\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.0825 - accuracy: 0.9200 - val_loss: 0.1671 - val_accuracy: 0.8278\n",
            "Epoch 670/1000\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.0820 - accuracy: 0.9350 - val_loss: 0.1655 - val_accuracy: 0.8212\n",
            "Epoch 671/1000\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0826 - accuracy: 0.9250 - val_loss: 0.1651 - val_accuracy: 0.8212\n",
            "Epoch 672/1000\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0820 - accuracy: 0.9250 - val_loss: 0.1654 - val_accuracy: 0.8278\n",
            "Epoch 673/1000\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.0825 - accuracy: 0.9350 - val_loss: 0.1660 - val_accuracy: 0.8278\n",
            "Epoch 674/1000\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.0819 - accuracy: 0.9300 - val_loss: 0.1673 - val_accuracy: 0.8344\n",
            "Epoch 675/1000\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0836 - accuracy: 0.9200 - val_loss: 0.1680 - val_accuracy: 0.8278\n",
            "Epoch 676/1000\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0823 - accuracy: 0.9300 - val_loss: 0.1672 - val_accuracy: 0.8278\n",
            "Epoch 677/1000\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0821 - accuracy: 0.9300 - val_loss: 0.1675 - val_accuracy: 0.8146\n",
            "Epoch 678/1000\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0829 - accuracy: 0.9250 - val_loss: 0.1678 - val_accuracy: 0.8146\n",
            "Epoch 679/1000\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0828 - accuracy: 0.9250 - val_loss: 0.1685 - val_accuracy: 0.8146\n",
            "Epoch 680/1000\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0827 - accuracy: 0.9250 - val_loss: 0.1703 - val_accuracy: 0.8146\n",
            "Epoch 681/1000\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0829 - accuracy: 0.9350 - val_loss: 0.1707 - val_accuracy: 0.8146\n",
            "Epoch 682/1000\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.0822 - accuracy: 0.9250 - val_loss: 0.1684 - val_accuracy: 0.8212\n",
            "Epoch 683/1000\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.0840 - accuracy: 0.9150 - val_loss: 0.1671 - val_accuracy: 0.8278\n",
            "Epoch 684/1000\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.0834 - accuracy: 0.9200 - val_loss: 0.1676 - val_accuracy: 0.8278\n",
            "Epoch 685/1000\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.0829 - accuracy: 0.9250 - val_loss: 0.1662 - val_accuracy: 0.8278\n",
            "Epoch 686/1000\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0823 - accuracy: 0.9250 - val_loss: 0.1655 - val_accuracy: 0.8278\n",
            "Epoch 687/1000\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0828 - accuracy: 0.9300 - val_loss: 0.1666 - val_accuracy: 0.8212\n",
            "Epoch 688/1000\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0822 - accuracy: 0.9250 - val_loss: 0.1675 - val_accuracy: 0.8212\n",
            "Epoch 689/1000\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.0822 - accuracy: 0.9200 - val_loss: 0.1677 - val_accuracy: 0.8212\n",
            "Epoch 690/1000\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.0819 - accuracy: 0.9250 - val_loss: 0.1675 - val_accuracy: 0.8212\n",
            "Epoch 691/1000\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0824 - accuracy: 0.9250 - val_loss: 0.1667 - val_accuracy: 0.8146\n",
            "Epoch 692/1000\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0832 - accuracy: 0.9350 - val_loss: 0.1643 - val_accuracy: 0.8146\n",
            "Epoch 693/1000\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0850 - accuracy: 0.9350 - val_loss: 0.1637 - val_accuracy: 0.8212\n",
            "Epoch 694/1000\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.0835 - accuracy: 0.9150 - val_loss: 0.1652 - val_accuracy: 0.8212\n",
            "Epoch 695/1000\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.0827 - accuracy: 0.9150 - val_loss: 0.1646 - val_accuracy: 0.8212\n",
            "Epoch 696/1000\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.0827 - accuracy: 0.9250 - val_loss: 0.1649 - val_accuracy: 0.8212\n",
            "Epoch 697/1000\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.0825 - accuracy: 0.9250 - val_loss: 0.1660 - val_accuracy: 0.8212\n",
            "Epoch 698/1000\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.0826 - accuracy: 0.9300 - val_loss: 0.1658 - val_accuracy: 0.8212\n",
            "Epoch 699/1000\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.0831 - accuracy: 0.9250 - val_loss: 0.1660 - val_accuracy: 0.8146\n",
            "Epoch 700/1000\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0826 - accuracy: 0.9300 - val_loss: 0.1672 - val_accuracy: 0.8212\n",
            "Epoch 701/1000\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.0821 - accuracy: 0.9300 - val_loss: 0.1681 - val_accuracy: 0.8079\n",
            "Epoch 702/1000\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0818 - accuracy: 0.9300 - val_loss: 0.1686 - val_accuracy: 0.8212\n",
            "Epoch 703/1000\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0833 - accuracy: 0.9200 - val_loss: 0.1681 - val_accuracy: 0.8146\n",
            "Epoch 704/1000\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0831 - accuracy: 0.9300 - val_loss: 0.1679 - val_accuracy: 0.8278\n",
            "Epoch 705/1000\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.0841 - accuracy: 0.9350 - val_loss: 0.1669 - val_accuracy: 0.8344\n",
            "Epoch 706/1000\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0829 - accuracy: 0.9350 - val_loss: 0.1664 - val_accuracy: 0.8344\n",
            "Epoch 707/1000\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0828 - accuracy: 0.9300 - val_loss: 0.1661 - val_accuracy: 0.8278\n",
            "Epoch 708/1000\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0818 - accuracy: 0.9350 - val_loss: 0.1675 - val_accuracy: 0.8278\n",
            "Epoch 709/1000\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.0834 - accuracy: 0.9300 - val_loss: 0.1686 - val_accuracy: 0.8212\n",
            "Epoch 710/1000\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.0836 - accuracy: 0.9200 - val_loss: 0.1695 - val_accuracy: 0.8278\n",
            "Epoch 711/1000\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0841 - accuracy: 0.9150 - val_loss: 0.1678 - val_accuracy: 0.8278\n",
            "Epoch 712/1000\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.0828 - accuracy: 0.9250 - val_loss: 0.1686 - val_accuracy: 0.8146\n",
            "Epoch 713/1000\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0826 - accuracy: 0.9350 - val_loss: 0.1691 - val_accuracy: 0.8146\n",
            "Epoch 714/1000\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.0828 - accuracy: 0.9200 - val_loss: 0.1687 - val_accuracy: 0.8212\n",
            "Epoch 715/1000\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0833 - accuracy: 0.9200 - val_loss: 0.1680 - val_accuracy: 0.8212\n",
            "Epoch 716/1000\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0824 - accuracy: 0.9200 - val_loss: 0.1685 - val_accuracy: 0.8146\n",
            "Epoch 717/1000\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0823 - accuracy: 0.9250 - val_loss: 0.1673 - val_accuracy: 0.8278\n",
            "Epoch 718/1000\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0827 - accuracy: 0.9200 - val_loss: 0.1662 - val_accuracy: 0.8344\n",
            "Epoch 719/1000\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0834 - accuracy: 0.9200 - val_loss: 0.1671 - val_accuracy: 0.8278\n",
            "Epoch 720/1000\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.0826 - accuracy: 0.9250 - val_loss: 0.1686 - val_accuracy: 0.8146\n",
            "Epoch 721/1000\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.0830 - accuracy: 0.9200 - val_loss: 0.1693 - val_accuracy: 0.8212\n",
            "Epoch 722/1000\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0824 - accuracy: 0.9200 - val_loss: 0.1678 - val_accuracy: 0.8344\n",
            "Epoch 723/1000\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0822 - accuracy: 0.9200 - val_loss: 0.1678 - val_accuracy: 0.8278\n",
            "Epoch 724/1000\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.0820 - accuracy: 0.9200 - val_loss: 0.1673 - val_accuracy: 0.8344\n",
            "Epoch 725/1000\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0822 - accuracy: 0.9250 - val_loss: 0.1669 - val_accuracy: 0.8212\n",
            "Epoch 726/1000\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.0826 - accuracy: 0.9250 - val_loss: 0.1664 - val_accuracy: 0.8146\n",
            "Epoch 727/1000\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0839 - accuracy: 0.9150 - val_loss: 0.1658 - val_accuracy: 0.8278\n",
            "Epoch 728/1000\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0821 - accuracy: 0.9250 - val_loss: 0.1672 - val_accuracy: 0.8212\n",
            "Epoch 729/1000\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0842 - accuracy: 0.9300 - val_loss: 0.1661 - val_accuracy: 0.8278\n",
            "Epoch 730/1000\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.0823 - accuracy: 0.9250 - val_loss: 0.1661 - val_accuracy: 0.8411\n",
            "Epoch 731/1000\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.0835 - accuracy: 0.9300 - val_loss: 0.1653 - val_accuracy: 0.8344\n",
            "Epoch 732/1000\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0821 - accuracy: 0.9350 - val_loss: 0.1650 - val_accuracy: 0.8477\n",
            "Epoch 733/1000\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0826 - accuracy: 0.9200 - val_loss: 0.1651 - val_accuracy: 0.8411\n",
            "Epoch 734/1000\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.0825 - accuracy: 0.9250 - val_loss: 0.1652 - val_accuracy: 0.8278\n",
            "Epoch 735/1000\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0823 - accuracy: 0.9250 - val_loss: 0.1647 - val_accuracy: 0.8344\n",
            "Epoch 736/1000\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0824 - accuracy: 0.9200 - val_loss: 0.1651 - val_accuracy: 0.8278\n",
            "Epoch 737/1000\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.0824 - accuracy: 0.9200 - val_loss: 0.1642 - val_accuracy: 0.8212\n",
            "Epoch 738/1000\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0819 - accuracy: 0.9250 - val_loss: 0.1650 - val_accuracy: 0.8212\n",
            "Epoch 739/1000\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.0821 - accuracy: 0.9300 - val_loss: 0.1661 - val_accuracy: 0.8278\n",
            "Epoch 740/1000\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.0818 - accuracy: 0.9300 - val_loss: 0.1658 - val_accuracy: 0.8344\n",
            "Epoch 741/1000\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0824 - accuracy: 0.9300 - val_loss: 0.1665 - val_accuracy: 0.8212\n",
            "Epoch 742/1000\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.0826 - accuracy: 0.9250 - val_loss: 0.1669 - val_accuracy: 0.8212\n",
            "Epoch 743/1000\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0820 - accuracy: 0.9250 - val_loss: 0.1678 - val_accuracy: 0.8146\n",
            "Epoch 744/1000\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.0820 - accuracy: 0.9300 - val_loss: 0.1667 - val_accuracy: 0.8079\n",
            "Epoch 745/1000\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.0829 - accuracy: 0.9250 - val_loss: 0.1670 - val_accuracy: 0.8212\n",
            "Epoch 746/1000\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0830 - accuracy: 0.9200 - val_loss: 0.1663 - val_accuracy: 0.8146\n",
            "Epoch 747/1000\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.0833 - accuracy: 0.9350 - val_loss: 0.1663 - val_accuracy: 0.8212\n",
            "Epoch 748/1000\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.0832 - accuracy: 0.9250 - val_loss: 0.1664 - val_accuracy: 0.8344\n",
            "Epoch 749/1000\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.0833 - accuracy: 0.9200 - val_loss: 0.1668 - val_accuracy: 0.8278\n",
            "Epoch 750/1000\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.0825 - accuracy: 0.9250 - val_loss: 0.1669 - val_accuracy: 0.8278\n",
            "Epoch 751/1000\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0820 - accuracy: 0.9300 - val_loss: 0.1662 - val_accuracy: 0.8146\n",
            "Epoch 752/1000\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.0822 - accuracy: 0.9250 - val_loss: 0.1674 - val_accuracy: 0.8212\n",
            "Epoch 753/1000\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0827 - accuracy: 0.9200 - val_loss: 0.1665 - val_accuracy: 0.8146\n",
            "Epoch 754/1000\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.0829 - accuracy: 0.9250 - val_loss: 0.1655 - val_accuracy: 0.8212\n",
            "Epoch 755/1000\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.0822 - accuracy: 0.9250 - val_loss: 0.1651 - val_accuracy: 0.8344\n",
            "Epoch 756/1000\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0832 - accuracy: 0.9200 - val_loss: 0.1654 - val_accuracy: 0.8278\n",
            "Epoch 757/1000\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0825 - accuracy: 0.9300 - val_loss: 0.1659 - val_accuracy: 0.8212\n",
            "Epoch 758/1000\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.0826 - accuracy: 0.9300 - val_loss: 0.1653 - val_accuracy: 0.8344\n",
            "Epoch 759/1000\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.0825 - accuracy: 0.9250 - val_loss: 0.1665 - val_accuracy: 0.8278\n",
            "Epoch 760/1000\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.0834 - accuracy: 0.9200 - val_loss: 0.1659 - val_accuracy: 0.8278\n",
            "Epoch 761/1000\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.0850 - accuracy: 0.9300 - val_loss: 0.1674 - val_accuracy: 0.8079\n",
            "Epoch 762/1000\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.0837 - accuracy: 0.9350 - val_loss: 0.1685 - val_accuracy: 0.8344\n",
            "Epoch 763/1000\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.0828 - accuracy: 0.9300 - val_loss: 0.1677 - val_accuracy: 0.8411\n",
            "Epoch 764/1000\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0827 - accuracy: 0.9350 - val_loss: 0.1664 - val_accuracy: 0.8344\n",
            "Epoch 765/1000\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.0839 - accuracy: 0.9350 - val_loss: 0.1658 - val_accuracy: 0.8344\n",
            "Epoch 766/1000\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0819 - accuracy: 0.9300 - val_loss: 0.1654 - val_accuracy: 0.8344\n",
            "Epoch 767/1000\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.0833 - accuracy: 0.9250 - val_loss: 0.1662 - val_accuracy: 0.8278\n",
            "Epoch 768/1000\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0831 - accuracy: 0.9300 - val_loss: 0.1665 - val_accuracy: 0.8278\n",
            "Epoch 769/1000\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0825 - accuracy: 0.9350 - val_loss: 0.1658 - val_accuracy: 0.8344\n",
            "Epoch 770/1000\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.0830 - accuracy: 0.9250 - val_loss: 0.1667 - val_accuracy: 0.8411\n",
            "Epoch 771/1000\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.0824 - accuracy: 0.9200 - val_loss: 0.1675 - val_accuracy: 0.8212\n",
            "Epoch 772/1000\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0840 - accuracy: 0.9300 - val_loss: 0.1701 - val_accuracy: 0.8278\n",
            "Epoch 773/1000\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0815 - accuracy: 0.9300 - val_loss: 0.1700 - val_accuracy: 0.8344\n",
            "Epoch 774/1000\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0832 - accuracy: 0.9250 - val_loss: 0.1678 - val_accuracy: 0.8212\n",
            "Epoch 775/1000\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.0822 - accuracy: 0.9250 - val_loss: 0.1667 - val_accuracy: 0.8278\n",
            "Epoch 776/1000\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0822 - accuracy: 0.9300 - val_loss: 0.1649 - val_accuracy: 0.8344\n",
            "Epoch 777/1000\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.0829 - accuracy: 0.9350 - val_loss: 0.1652 - val_accuracy: 0.8344\n",
            "Epoch 778/1000\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.0819 - accuracy: 0.9250 - val_loss: 0.1659 - val_accuracy: 0.8344\n",
            "Epoch 779/1000\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.0830 - accuracy: 0.9200 - val_loss: 0.1672 - val_accuracy: 0.8344\n",
            "Epoch 780/1000\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.0828 - accuracy: 0.9300 - val_loss: 0.1676 - val_accuracy: 0.8278\n",
            "Epoch 781/1000\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0824 - accuracy: 0.9250 - val_loss: 0.1673 - val_accuracy: 0.8212\n",
            "Epoch 782/1000\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.0837 - accuracy: 0.9150 - val_loss: 0.1667 - val_accuracy: 0.8212\n",
            "Epoch 783/1000\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0829 - accuracy: 0.9300 - val_loss: 0.1671 - val_accuracy: 0.8344\n",
            "Epoch 784/1000\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.0836 - accuracy: 0.9250 - val_loss: 0.1664 - val_accuracy: 0.8411\n",
            "Epoch 785/1000\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0825 - accuracy: 0.9300 - val_loss: 0.1659 - val_accuracy: 0.8411\n",
            "Epoch 786/1000\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.0826 - accuracy: 0.9300 - val_loss: 0.1644 - val_accuracy: 0.8411\n",
            "Epoch 787/1000\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.0823 - accuracy: 0.9300 - val_loss: 0.1642 - val_accuracy: 0.8411\n",
            "Epoch 788/1000\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0822 - accuracy: 0.9300 - val_loss: 0.1647 - val_accuracy: 0.8278\n",
            "Epoch 789/1000\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.0836 - accuracy: 0.9250 - val_loss: 0.1642 - val_accuracy: 0.8212\n",
            "Epoch 790/1000\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0826 - accuracy: 0.9300 - val_loss: 0.1648 - val_accuracy: 0.8278\n",
            "Epoch 791/1000\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0829 - accuracy: 0.9250 - val_loss: 0.1640 - val_accuracy: 0.8278\n",
            "Epoch 792/1000\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0829 - accuracy: 0.9250 - val_loss: 0.1646 - val_accuracy: 0.8212\n",
            "Epoch 793/1000\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0828 - accuracy: 0.9300 - val_loss: 0.1657 - val_accuracy: 0.8146\n",
            "Epoch 794/1000\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.0827 - accuracy: 0.9250 - val_loss: 0.1650 - val_accuracy: 0.8146\n",
            "Epoch 795/1000\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.0823 - accuracy: 0.9300 - val_loss: 0.1643 - val_accuracy: 0.8146\n",
            "Epoch 796/1000\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.0829 - accuracy: 0.9250 - val_loss: 0.1642 - val_accuracy: 0.8146\n",
            "Epoch 797/1000\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.0834 - accuracy: 0.9200 - val_loss: 0.1631 - val_accuracy: 0.8278\n",
            "Epoch 798/1000\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.0836 - accuracy: 0.9250 - val_loss: 0.1635 - val_accuracy: 0.8278\n",
            "Epoch 799/1000\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0824 - accuracy: 0.9250 - val_loss: 0.1645 - val_accuracy: 0.8278\n",
            "Epoch 800/1000\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0832 - accuracy: 0.9350 - val_loss: 0.1649 - val_accuracy: 0.8146\n",
            "Epoch 801/1000\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0830 - accuracy: 0.9250 - val_loss: 0.1649 - val_accuracy: 0.8212\n",
            "Epoch 802/1000\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.0827 - accuracy: 0.9250 - val_loss: 0.1649 - val_accuracy: 0.8212\n",
            "Epoch 803/1000\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0820 - accuracy: 0.9250 - val_loss: 0.1659 - val_accuracy: 0.8278\n",
            "Epoch 804/1000\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.0822 - accuracy: 0.9200 - val_loss: 0.1654 - val_accuracy: 0.8278\n",
            "Epoch 805/1000\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.0826 - accuracy: 0.9200 - val_loss: 0.1656 - val_accuracy: 0.8278\n",
            "Epoch 806/1000\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.0822 - accuracy: 0.9200 - val_loss: 0.1651 - val_accuracy: 0.8278\n",
            "Epoch 807/1000\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.0821 - accuracy: 0.9200 - val_loss: 0.1658 - val_accuracy: 0.8212\n",
            "Epoch 808/1000\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.0823 - accuracy: 0.9250 - val_loss: 0.1655 - val_accuracy: 0.8212\n",
            "Epoch 809/1000\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0828 - accuracy: 0.9200 - val_loss: 0.1658 - val_accuracy: 0.8278\n",
            "Epoch 810/1000\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.0821 - accuracy: 0.9250 - val_loss: 0.1660 - val_accuracy: 0.8212\n",
            "Epoch 811/1000\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.0821 - accuracy: 0.9300 - val_loss: 0.1651 - val_accuracy: 0.8278\n",
            "Epoch 812/1000\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.0826 - accuracy: 0.9350 - val_loss: 0.1635 - val_accuracy: 0.8411\n",
            "Epoch 813/1000\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0823 - accuracy: 0.9350 - val_loss: 0.1637 - val_accuracy: 0.8344\n",
            "Epoch 814/1000\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.0834 - accuracy: 0.9200 - val_loss: 0.1648 - val_accuracy: 0.8344\n",
            "Epoch 815/1000\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0844 - accuracy: 0.9200 - val_loss: 0.1656 - val_accuracy: 0.8212\n",
            "Epoch 816/1000\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0835 - accuracy: 0.9250 - val_loss: 0.1668 - val_accuracy: 0.8212\n",
            "Epoch 817/1000\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0829 - accuracy: 0.9150 - val_loss: 0.1676 - val_accuracy: 0.8212\n",
            "Epoch 818/1000\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.0834 - accuracy: 0.9300 - val_loss: 0.1680 - val_accuracy: 0.8212\n",
            "Epoch 819/1000\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.0830 - accuracy: 0.9250 - val_loss: 0.1673 - val_accuracy: 0.8344\n",
            "Epoch 820/1000\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.0831 - accuracy: 0.9250 - val_loss: 0.1671 - val_accuracy: 0.8344\n",
            "Epoch 821/1000\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.0832 - accuracy: 0.9250 - val_loss: 0.1677 - val_accuracy: 0.8278\n",
            "Epoch 822/1000\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0838 - accuracy: 0.9350 - val_loss: 0.1671 - val_accuracy: 0.8146\n",
            "Epoch 823/1000\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0835 - accuracy: 0.9300 - val_loss: 0.1659 - val_accuracy: 0.8212\n",
            "Epoch 824/1000\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.0838 - accuracy: 0.9250 - val_loss: 0.1692 - val_accuracy: 0.8212\n",
            "Epoch 825/1000\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.0831 - accuracy: 0.9250 - val_loss: 0.1697 - val_accuracy: 0.8146\n",
            "Epoch 826/1000\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.0823 - accuracy: 0.9250 - val_loss: 0.1683 - val_accuracy: 0.8212\n",
            "Epoch 827/1000\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.0827 - accuracy: 0.9200 - val_loss: 0.1671 - val_accuracy: 0.8212\n",
            "Epoch 828/1000\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.0828 - accuracy: 0.9200 - val_loss: 0.1679 - val_accuracy: 0.8278\n",
            "Epoch 829/1000\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.0837 - accuracy: 0.9300 - val_loss: 0.1701 - val_accuracy: 0.8079\n",
            "Epoch 830/1000\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0824 - accuracy: 0.9250 - val_loss: 0.1695 - val_accuracy: 0.8278\n",
            "Epoch 831/1000\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.0821 - accuracy: 0.9250 - val_loss: 0.1705 - val_accuracy: 0.8146\n",
            "Epoch 832/1000\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0824 - accuracy: 0.9200 - val_loss: 0.1707 - val_accuracy: 0.8146\n",
            "Epoch 833/1000\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.0832 - accuracy: 0.9200 - val_loss: 0.1705 - val_accuracy: 0.8146\n",
            "Epoch 834/1000\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0822 - accuracy: 0.9200 - val_loss: 0.1706 - val_accuracy: 0.8146\n",
            "Epoch 835/1000\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.0829 - accuracy: 0.9150 - val_loss: 0.1700 - val_accuracy: 0.8212\n",
            "Epoch 836/1000\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0821 - accuracy: 0.9200 - val_loss: 0.1699 - val_accuracy: 0.8146\n",
            "Epoch 837/1000\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.0825 - accuracy: 0.9200 - val_loss: 0.1702 - val_accuracy: 0.8146\n",
            "Epoch 838/1000\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.0833 - accuracy: 0.9200 - val_loss: 0.1699 - val_accuracy: 0.8146\n",
            "Epoch 839/1000\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.0834 - accuracy: 0.9250 - val_loss: 0.1728 - val_accuracy: 0.8013\n",
            "Epoch 840/1000\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0827 - accuracy: 0.9300 - val_loss: 0.1718 - val_accuracy: 0.8212\n",
            "Epoch 841/1000\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.0830 - accuracy: 0.9200 - val_loss: 0.1735 - val_accuracy: 0.8146\n",
            "Epoch 842/1000\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0841 - accuracy: 0.9300 - val_loss: 0.1740 - val_accuracy: 0.8146\n",
            "Epoch 843/1000\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.0839 - accuracy: 0.9300 - val_loss: 0.1709 - val_accuracy: 0.8146\n",
            "Epoch 844/1000\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.0832 - accuracy: 0.9300 - val_loss: 0.1696 - val_accuracy: 0.8212\n",
            "Epoch 845/1000\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.0827 - accuracy: 0.9250 - val_loss: 0.1681 - val_accuracy: 0.8146\n",
            "Epoch 846/1000\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.0820 - accuracy: 0.9250 - val_loss: 0.1681 - val_accuracy: 0.8278\n",
            "Epoch 847/1000\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.0824 - accuracy: 0.9250 - val_loss: 0.1687 - val_accuracy: 0.8278\n",
            "Epoch 848/1000\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.0841 - accuracy: 0.9200 - val_loss: 0.1690 - val_accuracy: 0.8212\n",
            "Epoch 849/1000\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0822 - accuracy: 0.9250 - val_loss: 0.1682 - val_accuracy: 0.8079\n",
            "Epoch 850/1000\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0825 - accuracy: 0.9250 - val_loss: 0.1695 - val_accuracy: 0.8146\n",
            "Epoch 851/1000\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0832 - accuracy: 0.9250 - val_loss: 0.1714 - val_accuracy: 0.8079\n",
            "Epoch 852/1000\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0831 - accuracy: 0.9300 - val_loss: 0.1709 - val_accuracy: 0.8079\n",
            "Epoch 853/1000\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.0823 - accuracy: 0.9250 - val_loss: 0.1706 - val_accuracy: 0.8146\n",
            "Epoch 854/1000\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.0824 - accuracy: 0.9250 - val_loss: 0.1708 - val_accuracy: 0.8212\n",
            "Epoch 855/1000\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.0828 - accuracy: 0.9200 - val_loss: 0.1708 - val_accuracy: 0.8146\n",
            "Epoch 856/1000\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.0818 - accuracy: 0.9250 - val_loss: 0.1709 - val_accuracy: 0.8212\n",
            "Epoch 857/1000\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.0827 - accuracy: 0.9200 - val_loss: 0.1713 - val_accuracy: 0.8146\n",
            "Epoch 858/1000\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0825 - accuracy: 0.9250 - val_loss: 0.1724 - val_accuracy: 0.8146\n",
            "Epoch 859/1000\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.0824 - accuracy: 0.9250 - val_loss: 0.1731 - val_accuracy: 0.8212\n",
            "Epoch 860/1000\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0826 - accuracy: 0.9300 - val_loss: 0.1735 - val_accuracy: 0.8212\n",
            "Epoch 861/1000\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.0824 - accuracy: 0.9300 - val_loss: 0.1728 - val_accuracy: 0.8212\n",
            "Epoch 862/1000\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.0821 - accuracy: 0.9250 - val_loss: 0.1716 - val_accuracy: 0.8212\n",
            "Epoch 863/1000\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0822 - accuracy: 0.9200 - val_loss: 0.1717 - val_accuracy: 0.8212\n",
            "Epoch 864/1000\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.0820 - accuracy: 0.9200 - val_loss: 0.1728 - val_accuracy: 0.8146\n",
            "Epoch 865/1000\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0839 - accuracy: 0.9400 - val_loss: 0.1713 - val_accuracy: 0.8146\n",
            "Epoch 866/1000\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0848 - accuracy: 0.9200 - val_loss: 0.1713 - val_accuracy: 0.8278\n",
            "Epoch 867/1000\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.0840 - accuracy: 0.9200 - val_loss: 0.1732 - val_accuracy: 0.8146\n",
            "Epoch 868/1000\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0826 - accuracy: 0.9300 - val_loss: 0.1718 - val_accuracy: 0.8079\n",
            "Epoch 869/1000\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.0834 - accuracy: 0.9300 - val_loss: 0.1711 - val_accuracy: 0.8079\n",
            "Epoch 870/1000\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.0817 - accuracy: 0.9300 - val_loss: 0.1702 - val_accuracy: 0.8146\n",
            "Epoch 871/1000\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.0829 - accuracy: 0.9150 - val_loss: 0.1707 - val_accuracy: 0.8146\n",
            "Epoch 872/1000\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.0832 - accuracy: 0.9150 - val_loss: 0.1704 - val_accuracy: 0.8212\n",
            "Epoch 873/1000\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.0827 - accuracy: 0.9250 - val_loss: 0.1708 - val_accuracy: 0.8146\n",
            "Epoch 874/1000\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.0826 - accuracy: 0.9300 - val_loss: 0.1712 - val_accuracy: 0.8146\n",
            "Epoch 875/1000\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.0817 - accuracy: 0.9250 - val_loss: 0.1721 - val_accuracy: 0.8146\n",
            "Epoch 876/1000\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0827 - accuracy: 0.9300 - val_loss: 0.1729 - val_accuracy: 0.8146\n",
            "Epoch 877/1000\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0821 - accuracy: 0.9250 - val_loss: 0.1718 - val_accuracy: 0.8146\n",
            "Epoch 878/1000\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0820 - accuracy: 0.9200 - val_loss: 0.1716 - val_accuracy: 0.8212\n",
            "Epoch 879/1000\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0824 - accuracy: 0.9250 - val_loss: 0.1717 - val_accuracy: 0.8278\n",
            "Epoch 880/1000\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.0824 - accuracy: 0.9250 - val_loss: 0.1722 - val_accuracy: 0.8146\n",
            "Epoch 881/1000\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.0821 - accuracy: 0.9350 - val_loss: 0.1714 - val_accuracy: 0.8079\n",
            "Epoch 882/1000\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0826 - accuracy: 0.9250 - val_loss: 0.1702 - val_accuracy: 0.8146\n",
            "Epoch 883/1000\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.0822 - accuracy: 0.9250 - val_loss: 0.1721 - val_accuracy: 0.8212\n",
            "Epoch 884/1000\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.0826 - accuracy: 0.9300 - val_loss: 0.1724 - val_accuracy: 0.8278\n",
            "Epoch 885/1000\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.0832 - accuracy: 0.9200 - val_loss: 0.1715 - val_accuracy: 0.8278\n",
            "Epoch 886/1000\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.0824 - accuracy: 0.9250 - val_loss: 0.1708 - val_accuracy: 0.8146\n",
            "Epoch 887/1000\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.0823 - accuracy: 0.9250 - val_loss: 0.1706 - val_accuracy: 0.8212\n",
            "Epoch 888/1000\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.0822 - accuracy: 0.9250 - val_loss: 0.1699 - val_accuracy: 0.8212\n",
            "Epoch 889/1000\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0839 - accuracy: 0.9300 - val_loss: 0.1705 - val_accuracy: 0.8212\n",
            "Epoch 890/1000\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0824 - accuracy: 0.9300 - val_loss: 0.1702 - val_accuracy: 0.8278\n",
            "Epoch 891/1000\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.0837 - accuracy: 0.9250 - val_loss: 0.1706 - val_accuracy: 0.8278\n",
            "Epoch 892/1000\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.0824 - accuracy: 0.9200 - val_loss: 0.1711 - val_accuracy: 0.8278\n",
            "Epoch 893/1000\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0843 - accuracy: 0.9300 - val_loss: 0.1687 - val_accuracy: 0.8146\n",
            "Epoch 894/1000\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.0830 - accuracy: 0.9350 - val_loss: 0.1663 - val_accuracy: 0.8278\n",
            "Epoch 895/1000\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.0837 - accuracy: 0.9300 - val_loss: 0.1669 - val_accuracy: 0.8278\n",
            "Epoch 896/1000\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0833 - accuracy: 0.9200 - val_loss: 0.1675 - val_accuracy: 0.8344\n",
            "Epoch 897/1000\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.0837 - accuracy: 0.9200 - val_loss: 0.1673 - val_accuracy: 0.8278\n",
            "Epoch 898/1000\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0824 - accuracy: 0.9300 - val_loss: 0.1658 - val_accuracy: 0.8344\n",
            "Epoch 899/1000\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.0821 - accuracy: 0.9350 - val_loss: 0.1675 - val_accuracy: 0.8278\n",
            "Epoch 900/1000\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.0824 - accuracy: 0.9300 - val_loss: 0.1684 - val_accuracy: 0.8278\n",
            "Epoch 901/1000\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.0823 - accuracy: 0.9300 - val_loss: 0.1684 - val_accuracy: 0.8278\n",
            "Epoch 902/1000\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.0825 - accuracy: 0.9250 - val_loss: 0.1704 - val_accuracy: 0.8079\n",
            "Epoch 903/1000\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.0824 - accuracy: 0.9250 - val_loss: 0.1713 - val_accuracy: 0.8146\n",
            "Epoch 904/1000\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.0840 - accuracy: 0.9350 - val_loss: 0.1715 - val_accuracy: 0.8146\n",
            "Epoch 905/1000\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.0833 - accuracy: 0.9200 - val_loss: 0.1717 - val_accuracy: 0.8212\n",
            "Epoch 906/1000\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.0853 - accuracy: 0.9100 - val_loss: 0.1693 - val_accuracy: 0.8344\n",
            "Epoch 907/1000\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.0819 - accuracy: 0.9250 - val_loss: 0.1693 - val_accuracy: 0.8344\n",
            "Epoch 908/1000\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.0848 - accuracy: 0.9350 - val_loss: 0.1688 - val_accuracy: 0.8344\n",
            "Epoch 909/1000\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.0817 - accuracy: 0.9300 - val_loss: 0.1691 - val_accuracy: 0.8278\n",
            "Epoch 910/1000\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0841 - accuracy: 0.9100 - val_loss: 0.1696 - val_accuracy: 0.8146\n",
            "Epoch 911/1000\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.0827 - accuracy: 0.9200 - val_loss: 0.1696 - val_accuracy: 0.8212\n",
            "Epoch 912/1000\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.0827 - accuracy: 0.9300 - val_loss: 0.1699 - val_accuracy: 0.8278\n",
            "Epoch 913/1000\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.0822 - accuracy: 0.9300 - val_loss: 0.1695 - val_accuracy: 0.8212\n",
            "Epoch 914/1000\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.0839 - accuracy: 0.9200 - val_loss: 0.1684 - val_accuracy: 0.8278\n",
            "Epoch 915/1000\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0830 - accuracy: 0.9250 - val_loss: 0.1702 - val_accuracy: 0.8212\n",
            "Epoch 916/1000\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.0825 - accuracy: 0.9300 - val_loss: 0.1704 - val_accuracy: 0.8278\n",
            "Epoch 917/1000\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.0831 - accuracy: 0.9100 - val_loss: 0.1698 - val_accuracy: 0.8278\n",
            "Epoch 918/1000\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.0829 - accuracy: 0.9200 - val_loss: 0.1708 - val_accuracy: 0.8146\n",
            "Epoch 919/1000\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.0827 - accuracy: 0.9350 - val_loss: 0.1704 - val_accuracy: 0.8278\n",
            "Epoch 920/1000\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.0830 - accuracy: 0.9300 - val_loss: 0.1702 - val_accuracy: 0.8278\n",
            "Epoch 921/1000\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.0827 - accuracy: 0.9350 - val_loss: 0.1715 - val_accuracy: 0.8278\n",
            "Epoch 922/1000\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.0829 - accuracy: 0.9250 - val_loss: 0.1706 - val_accuracy: 0.8344\n",
            "Epoch 923/1000\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.0824 - accuracy: 0.9250 - val_loss: 0.1701 - val_accuracy: 0.8278\n",
            "Epoch 924/1000\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.0819 - accuracy: 0.9350 - val_loss: 0.1695 - val_accuracy: 0.8212\n",
            "Epoch 925/1000\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.0825 - accuracy: 0.9250 - val_loss: 0.1690 - val_accuracy: 0.8278\n",
            "Epoch 926/1000\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.0821 - accuracy: 0.9250 - val_loss: 0.1681 - val_accuracy: 0.8212\n",
            "Epoch 927/1000\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.0820 - accuracy: 0.9250 - val_loss: 0.1686 - val_accuracy: 0.8212\n",
            "Epoch 928/1000\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.0827 - accuracy: 0.9350 - val_loss: 0.1712 - val_accuracy: 0.8079\n",
            "Epoch 929/1000\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.0831 - accuracy: 0.9250 - val_loss: 0.1704 - val_accuracy: 0.8146\n",
            "Epoch 930/1000\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.0835 - accuracy: 0.9200 - val_loss: 0.1696 - val_accuracy: 0.8212\n",
            "Epoch 931/1000\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.0835 - accuracy: 0.9300 - val_loss: 0.1697 - val_accuracy: 0.8212\n",
            "Epoch 932/1000\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.0823 - accuracy: 0.9350 - val_loss: 0.1696 - val_accuracy: 0.8212\n",
            "Epoch 933/1000\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.0824 - accuracy: 0.9300 - val_loss: 0.1692 - val_accuracy: 0.8212\n",
            "Epoch 934/1000\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.0818 - accuracy: 0.9300 - val_loss: 0.1703 - val_accuracy: 0.8146\n",
            "Epoch 935/1000\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.0828 - accuracy: 0.9200 - val_loss: 0.1715 - val_accuracy: 0.8212\n",
            "Epoch 936/1000\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.0831 - accuracy: 0.9250 - val_loss: 0.1729 - val_accuracy: 0.8212\n",
            "Epoch 937/1000\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.0826 - accuracy: 0.9250 - val_loss: 0.1695 - val_accuracy: 0.8344\n",
            "Epoch 938/1000\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.0825 - accuracy: 0.9250 - val_loss: 0.1687 - val_accuracy: 0.8278\n",
            "Epoch 939/1000\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0824 - accuracy: 0.9250 - val_loss: 0.1689 - val_accuracy: 0.8212\n",
            "Epoch 940/1000\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0831 - accuracy: 0.9300 - val_loss: 0.1694 - val_accuracy: 0.8146\n",
            "Epoch 941/1000\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0823 - accuracy: 0.9250 - val_loss: 0.1695 - val_accuracy: 0.8278\n",
            "Epoch 942/1000\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.0826 - accuracy: 0.9250 - val_loss: 0.1696 - val_accuracy: 0.8212\n",
            "Epoch 943/1000\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.0832 - accuracy: 0.9250 - val_loss: 0.1692 - val_accuracy: 0.8212\n",
            "Epoch 944/1000\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.0826 - accuracy: 0.9250 - val_loss: 0.1675 - val_accuracy: 0.8212\n",
            "Epoch 945/1000\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.0823 - accuracy: 0.9250 - val_loss: 0.1681 - val_accuracy: 0.8146\n",
            "Epoch 946/1000\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.0825 - accuracy: 0.9350 - val_loss: 0.1686 - val_accuracy: 0.8146\n",
            "Epoch 947/1000\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.0822 - accuracy: 0.9250 - val_loss: 0.1701 - val_accuracy: 0.8212\n",
            "Epoch 948/1000\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.0829 - accuracy: 0.9200 - val_loss: 0.1707 - val_accuracy: 0.8278\n",
            "Epoch 949/1000\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0825 - accuracy: 0.9200 - val_loss: 0.1718 - val_accuracy: 0.8212\n",
            "Epoch 950/1000\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.0825 - accuracy: 0.9200 - val_loss: 0.1728 - val_accuracy: 0.8278\n",
            "Epoch 951/1000\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.0830 - accuracy: 0.9200 - val_loss: 0.1733 - val_accuracy: 0.8278\n",
            "Epoch 952/1000\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.0837 - accuracy: 0.9300 - val_loss: 0.1716 - val_accuracy: 0.8278\n",
            "Epoch 953/1000\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.0830 - accuracy: 0.9250 - val_loss: 0.1702 - val_accuracy: 0.8411\n",
            "Epoch 954/1000\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.0822 - accuracy: 0.9300 - val_loss: 0.1690 - val_accuracy: 0.8344\n",
            "Epoch 955/1000\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.0821 - accuracy: 0.9300 - val_loss: 0.1682 - val_accuracy: 0.8344\n",
            "Epoch 956/1000\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.0823 - accuracy: 0.9300 - val_loss: 0.1688 - val_accuracy: 0.8344\n",
            "Epoch 957/1000\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.0825 - accuracy: 0.9350 - val_loss: 0.1688 - val_accuracy: 0.8344\n",
            "Epoch 958/1000\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0818 - accuracy: 0.9250 - val_loss: 0.1687 - val_accuracy: 0.8344\n",
            "Epoch 959/1000\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.0831 - accuracy: 0.9200 - val_loss: 0.1690 - val_accuracy: 0.8278\n",
            "Epoch 960/1000\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.0813 - accuracy: 0.9350 - val_loss: 0.1718 - val_accuracy: 0.8079\n",
            "Epoch 961/1000\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.0837 - accuracy: 0.9350 - val_loss: 0.1705 - val_accuracy: 0.8212\n",
            "Epoch 962/1000\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0816 - accuracy: 0.9250 - val_loss: 0.1701 - val_accuracy: 0.8344\n",
            "Epoch 963/1000\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.0830 - accuracy: 0.9150 - val_loss: 0.1708 - val_accuracy: 0.8278\n",
            "Epoch 964/1000\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.0828 - accuracy: 0.9250 - val_loss: 0.1718 - val_accuracy: 0.8212\n",
            "Epoch 965/1000\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.0821 - accuracy: 0.9300 - val_loss: 0.1717 - val_accuracy: 0.8212\n",
            "Epoch 966/1000\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.0835 - accuracy: 0.9150 - val_loss: 0.1706 - val_accuracy: 0.8278\n",
            "Epoch 967/1000\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.0825 - accuracy: 0.9300 - val_loss: 0.1727 - val_accuracy: 0.8146\n",
            "Epoch 968/1000\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.0836 - accuracy: 0.9350 - val_loss: 0.1711 - val_accuracy: 0.8278\n",
            "Epoch 969/1000\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.0831 - accuracy: 0.9250 - val_loss: 0.1723 - val_accuracy: 0.8278\n",
            "Epoch 970/1000\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.0828 - accuracy: 0.9250 - val_loss: 0.1726 - val_accuracy: 0.8212\n",
            "Epoch 971/1000\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0818 - accuracy: 0.9200 - val_loss: 0.1723 - val_accuracy: 0.8212\n",
            "Epoch 972/1000\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0827 - accuracy: 0.9250 - val_loss: 0.1697 - val_accuracy: 0.8212\n",
            "Epoch 973/1000\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0828 - accuracy: 0.9250 - val_loss: 0.1702 - val_accuracy: 0.8212\n",
            "Epoch 974/1000\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.0822 - accuracy: 0.9250 - val_loss: 0.1690 - val_accuracy: 0.8278\n",
            "Epoch 975/1000\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.0824 - accuracy: 0.9250 - val_loss: 0.1689 - val_accuracy: 0.8212\n",
            "Epoch 976/1000\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.0823 - accuracy: 0.9300 - val_loss: 0.1695 - val_accuracy: 0.8278\n",
            "Epoch 977/1000\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.0832 - accuracy: 0.9150 - val_loss: 0.1693 - val_accuracy: 0.8278\n",
            "Epoch 978/1000\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.0812 - accuracy: 0.9300 - val_loss: 0.1688 - val_accuracy: 0.8146\n",
            "Epoch 979/1000\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.0845 - accuracy: 0.9350 - val_loss: 0.1665 - val_accuracy: 0.8212\n",
            "Epoch 980/1000\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.0836 - accuracy: 0.9200 - val_loss: 0.1671 - val_accuracy: 0.8278\n",
            "Epoch 981/1000\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.0832 - accuracy: 0.9200 - val_loss: 0.1682 - val_accuracy: 0.8344\n",
            "Epoch 982/1000\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.0825 - accuracy: 0.9250 - val_loss: 0.1682 - val_accuracy: 0.8278\n",
            "Epoch 983/1000\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0832 - accuracy: 0.9300 - val_loss: 0.1681 - val_accuracy: 0.8344\n",
            "Epoch 984/1000\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0823 - accuracy: 0.9300 - val_loss: 0.1673 - val_accuracy: 0.8344\n",
            "Epoch 985/1000\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.0822 - accuracy: 0.9300 - val_loss: 0.1687 - val_accuracy: 0.8278\n",
            "Epoch 986/1000\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0822 - accuracy: 0.9300 - val_loss: 0.1685 - val_accuracy: 0.8278\n",
            "Epoch 987/1000\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.0821 - accuracy: 0.9300 - val_loss: 0.1690 - val_accuracy: 0.8344\n",
            "Epoch 988/1000\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.0823 - accuracy: 0.9300 - val_loss: 0.1687 - val_accuracy: 0.8278\n",
            "Epoch 989/1000\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.0826 - accuracy: 0.9300 - val_loss: 0.1694 - val_accuracy: 0.8278\n",
            "Epoch 990/1000\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.0822 - accuracy: 0.9350 - val_loss: 0.1678 - val_accuracy: 0.8212\n",
            "Epoch 991/1000\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0820 - accuracy: 0.9250 - val_loss: 0.1688 - val_accuracy: 0.8212\n",
            "Epoch 992/1000\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.0827 - accuracy: 0.9250 - val_loss: 0.1687 - val_accuracy: 0.8212\n",
            "Epoch 993/1000\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.0815 - accuracy: 0.9250 - val_loss: 0.1691 - val_accuracy: 0.8278\n",
            "Epoch 994/1000\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.0829 - accuracy: 0.9300 - val_loss: 0.1703 - val_accuracy: 0.8278\n",
            "Epoch 995/1000\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.0821 - accuracy: 0.9300 - val_loss: 0.1704 - val_accuracy: 0.8344\n",
            "Epoch 996/1000\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.0824 - accuracy: 0.9250 - val_loss: 0.1691 - val_accuracy: 0.8212\n",
            "Epoch 997/1000\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0834 - accuracy: 0.9300 - val_loss: 0.1708 - val_accuracy: 0.8146\n",
            "Epoch 998/1000\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.0835 - accuracy: 0.9250 - val_loss: 0.1691 - val_accuracy: 0.8212\n",
            "Epoch 999/1000\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.0824 - accuracy: 0.9200 - val_loss: 0.1683 - val_accuracy: 0.8146\n",
            "Epoch 1000/1000\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0822 - accuracy: 0.9250 - val_loss: 0.1682 - val_accuracy: 0.8079\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "akurasi_model = hist.history['accuracy']\n",
        "loss_model = hist.history['loss']\n",
        "val_akurasi = hist.history['val_accuracy']\n",
        "val_loss = hist.history['val_loss']"
      ],
      "metadata": {
        "id": "HGaaLJ6VWuu6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(akurasi_model[-1])\n",
        "model.evaluate(X_test, Y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wWiV9jKKW-PU",
        "outputId": "bdc523bb-3bbb-4712-e618-fe33717ab36a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.925000011920929\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.1682 - accuracy: 0.8079\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.16822445392608643, 0.807947039604187]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_akurasi_model = 0\n",
        "for i in range(epoch):\n",
        "  if akurasi_model[i] > max_akurasi_model:\n",
        "    max_akurasi_model = akurasi_model[i]\n",
        "    j = i + 1\n",
        "val_akurasi_j = val_akurasi[j]"
      ],
      "metadata": {
        "id": "6veG_W4_4ty9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_val_akurasi = 0\n",
        "for i in range(epoch):\n",
        "  if val_akurasi[i] > max_val_akurasi:\n",
        "    max_val_akurasi = val_akurasi[i]\n",
        "    k = i + 1\n",
        "akurasi_model_k = akurasi_model[k]"
      ],
      "metadata": {
        "id": "XIW440P1dCbx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_akurasi_model = '{:.2%}'.format(max_akurasi_model)\n",
        "val_akurasi_j = '{:.2%}'.format(val_akurasi_j)\n",
        "print(f\"Model mendapatkan jumlah akurasi training tertinggi {max_akurasi_model} pada epoch ke- {j}\")\n",
        "print(\"Akurasi testing pada akurasi model training tertinggi adalah \" + val_akurasi_j)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CxPSkSNvphWT",
        "outputId": "e2d2653d-3e4c-4342-9f3e-7151792611be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model mendapatkan jumlah akurasi training tertinggi 94.00% pada epoch ke- 58\n",
            "Akurasi testing pada akurasi model training tertinggi adalah 83.44%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_val_akurasi = '{:.2%}'.format(max_val_akurasi)\n",
        "akurasi_model_k = '{:.2%}'.format(akurasi_model_k)\n",
        "print(f\"Model mendapatkan jumlah akurasi testing tertinggi {max_val_akurasi} pada epoch ke- {k}\")\n",
        "print(\"Akurasi training pada akurasi model testing tertinggi adalah \" + akurasi_model_k)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "80j81tqNdWkQ",
        "outputId": "e4f8576a-d6d4-4256-ec5f-d56a4cbdc52e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model mendapatkan jumlah akurasi testing tertinggi 84.77% pada epoch ke- 110\n",
            "Akurasi training pada akurasi model testing tertinggi adalah 93.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "akurasi = '{:.2%}'.format(sum(hist.history['accuracy'])/len(hist.history['accuracy']))\n",
        "print(f\"Model mendapatkan rata-rata akurasi sebesar {akurasi} dengan jumlah epoch {epoch}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ZcF-IBi5tUN",
        "outputId": "30408a46-786d-4203-da6c-7fedb81e2835"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model mendapatkan rata-rata akurasi sebesar 92.34% dengan jumlah epoch 1000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ploting\n",
        "epochs_range = range(epoch)\n",
        "\n",
        "plt.figure(figsize=(20, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, akurasi_model, label='Akurasi Training')\n",
        "plt.plot(epochs_range, val_akurasi, label='Akurasi Testing')\n",
        "plt.legend(loc='lower right')\n",
        "plt.ylim([0, 1])\n",
        "plt.title('Akurasi Training dan Testing')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss_model, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Testing Loss')\n",
        "plt.legend(loc='upper left')\n",
        "plt.title('Training dan Testing Loss')\n",
        "plt.ylim([0, 1])\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 499
        },
        "id": "7PHwiq3vCJio",
        "outputId": "3602a5e3-7711-47bf-8f45-398558c9ff12"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1440x576 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}